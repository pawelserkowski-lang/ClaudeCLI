{
    "providers":  {
                      "anthropic":  {
                                        "name":  "Anthropic",
                                        "baseUrl":  "https://api.anthropic.com/v1",
                                        "apiKeyEnv":  "ANTHROPIC_API_KEY",
                                        "priority":  1,
                                        "enabled":  true,
                                        "models":  {
                                                       "claude-3-5-haiku-20241022":  {
                                                                                         "tokensPerMinute":  999999,
                                                                                         "outputCost":  4,
                                                                                         "capabilities":  [
                                                                                                              "code",
                                                                                                              "analysis"
                                                                                                          ],
                                                                                         "parameterSize":  null,
                                                                                         "contextWindow":  200000,
                                                                                         "sizeGB":  null,
                                                                                         "inputCost":  0.8,
                                                                                         "tier":  "lite",
                                                                                         "requestsPerMinute":  999999,
                                                                                         "maxOutput":  8192
                                                                                     },
                                                       "claude-3-5-sonnet-20241022":  {
                                                                                          "tokensPerMinute":  999999,
                                                                                          "outputCost":  15,
                                                                                          "capabilities":  [
                                                                                                               "vision",
                                                                                                               "code",
                                                                                                               "analysis"
                                                                                                           ],
                                                                                          "parameterSize":  null,
                                                                                          "contextWindow":  200000,
                                                                                          "sizeGB":  null,
                                                                                          "inputCost":  3,
                                                                                          "tier":  "standard",
                                                                                          "requestsPerMinute":  999999,
                                                                                          "maxOutput":  8192
                                                                                      },
                                                       "claude-opus-4-20250514":  {
                                                                                      "tokensPerMinute":  999999,
                                                                                      "outputCost":  75,
                                                                                      "capabilities":  [
                                                                                                           "vision",
                                                                                                           "code",
                                                                                                           "analysis",
                                                                                                           "creative",
                                                                                                           "extended_thinking"
                                                                                                       ],
                                                                                      "parameterSize":  null,
                                                                                      "contextWindow":  200000,
                                                                                      "sizeGB":  null,
                                                                                      "inputCost":  15,
                                                                                      "tier":  "flagship",
                                                                                      "requestsPerMinute":  999999,
                                                                                      "maxOutput":  32000
                                                                                  },
                                                       "claude-sonnet-4-20250514":  {
                                                                                        "tokensPerMinute":  999999,
                                                                                        "outputCost":  15,
                                                                                        "capabilities":  [
                                                                                                             "vision",
                                                                                                             "code",
                                                                                                             "analysis",
                                                                                                             "creative"
                                                                                                         ],
                                                                                        "parameterSize":  null,
                                                                                        "contextWindow":  200000,
                                                                                        "sizeGB":  null,
                                                                                        "inputCost":  3,
                                                                                        "tier":  "pro",
                                                                                        "requestsPerMinute":  999999,
                                                                                        "maxOutput":  16000
                                                                                    }
                                                   }
                                    },
                      "openai":  {
                                     "name":  "OpenAI",
                                     "baseUrl":  "https://api.openai.com/v1",
                                     "apiKeyEnv":  "OPENAI_API_KEY",
                                     "priority":  2,
                                     "enabled":  true,
                                     "models":  {
                                                    "gpt-3.5-turbo-16k":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  1.5,
                                                                              "capabilities":  [
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  0.5,
                                                                              "tier":  "standard",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          },
                                                    "gpt-4o-mini-transcribe-2025-12-15":  {
                                                                                              "tokensPerMinute":  999999,
                                                                                              "outputCost":  0.6,
                                                                                              "capabilities":  [
                                                                                                                   "code",
                                                                                                                   "analysis"
                                                                                                               ],
                                                                                              "parameterSize":  null,
                                                                                              "contextWindow":  128000,
                                                                                              "sizeGB":  null,
                                                                                              "inputCost":  0.15,
                                                                                              "tier":  "lite",
                                                                                              "requestsPerMinute":  999999,
                                                                                              "maxOutput":  16384
                                                                                          },
                                                    "gpt-4o-search-preview-2025-03-11":  {
                                                                                             "tokensPerMinute":  999999,
                                                                                             "outputCost":  10,
                                                                                             "capabilities":  [
                                                                                                                  "vision",
                                                                                                                  "code",
                                                                                                                  "analysis"
                                                                                                              ],
                                                                                             "parameterSize":  null,
                                                                                             "contextWindow":  128000,
                                                                                             "sizeGB":  null,
                                                                                             "inputCost":  2.5,
                                                                                             "tier":  "pro",
                                                                                             "requestsPerMinute":  999999,
                                                                                             "maxOutput":  16384
                                                                                         },
                                                    "gpt-4.1":  {
                                                                    "tokensPerMinute":  999999,
                                                                    "outputCost":  1.5,
                                                                    "capabilities":  [
                                                                                         "code",
                                                                                         "analysis"
                                                                                     ],
                                                                    "parameterSize":  null,
                                                                    "contextWindow":  128000,
                                                                    "sizeGB":  null,
                                                                    "inputCost":  0.5,
                                                                    "tier":  "standard",
                                                                    "requestsPerMinute":  999999,
                                                                    "maxOutput":  16384
                                                                },
                                                    "gpt-4-turbo-preview":  {
                                                                                "tokensPerMinute":  999999,
                                                                                "outputCost":  30,
                                                                                "capabilities":  [
                                                                                                     "vision",
                                                                                                     "code",
                                                                                                     "analysis"
                                                                                                 ],
                                                                                "parameterSize":  null,
                                                                                "contextWindow":  128000,
                                                                                "sizeGB":  null,
                                                                                "inputCost":  10,
                                                                                "tier":  "pro",
                                                                                "requestsPerMinute":  999999,
                                                                                "maxOutput":  16384
                                                                            },
                                                    "gpt-4o-mini-tts-2025-12-15":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0.6,
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0.15,
                                                                                       "tier":  "lite",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  16384
                                                                                   },
                                                    "o3-2025-04-16":  {
                                                                          "tokensPerMinute":  999999,
                                                                          "outputCost":  1.5,
                                                                          "capabilities":  [
                                                                                               "code",
                                                                                               "analysis"
                                                                                           ],
                                                                          "parameterSize":  null,
                                                                          "contextWindow":  128000,
                                                                          "sizeGB":  null,
                                                                          "inputCost":  0.5,
                                                                          "tier":  "standard",
                                                                          "requestsPerMinute":  999999,
                                                                          "maxOutput":  16384
                                                                      },
                                                    "gpt-4o-mini-search-preview-2025-03-11":  {
                                                                                                  "tokensPerMinute":  999999,
                                                                                                  "outputCost":  0.6,
                                                                                                  "capabilities":  [
                                                                                                                       "code",
                                                                                                                       "analysis"
                                                                                                                   ],
                                                                                                  "parameterSize":  null,
                                                                                                  "contextWindow":  128000,
                                                                                                  "sizeGB":  null,
                                                                                                  "inputCost":  0.15,
                                                                                                  "tier":  "lite",
                                                                                                  "requestsPerMinute":  999999,
                                                                                                  "maxOutput":  16384
                                                                                              },
                                                    "gpt-4o-transcribe-diarize":  {
                                                                                      "tokensPerMinute":  999999,
                                                                                      "outputCost":  10,
                                                                                      "capabilities":  [
                                                                                                           "vision",
                                                                                                           "code",
                                                                                                           "analysis"
                                                                                                       ],
                                                                                      "parameterSize":  null,
                                                                                      "contextWindow":  128000,
                                                                                      "sizeGB":  null,
                                                                                      "inputCost":  2.5,
                                                                                      "tier":  "pro",
                                                                                      "requestsPerMinute":  999999,
                                                                                      "maxOutput":  16384
                                                                                  },
                                                    "gpt-4-0125-preview":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  1.5,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0.5,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "gpt-4o-mini":  {
                                                                        "tokensPerMinute":  999999,
                                                                        "outputCost":  0.6,
                                                                        "capabilities":  [
                                                                                             "code",
                                                                                             "analysis"
                                                                                         ],
                                                                        "parameterSize":  null,
                                                                        "contextWindow":  128000,
                                                                        "sizeGB":  null,
                                                                        "inputCost":  0.15,
                                                                        "tier":  "lite",
                                                                        "requestsPerMinute":  999999,
                                                                        "maxOutput":  16384
                                                                    },
                                                    "o3":  {
                                                               "tokensPerMinute":  999999,
                                                               "outputCost":  1.5,
                                                               "capabilities":  [
                                                                                    "code",
                                                                                    "analysis"
                                                                                ],
                                                               "parameterSize":  null,
                                                               "contextWindow":  128000,
                                                               "sizeGB":  null,
                                                               "inputCost":  0.5,
                                                               "tier":  "standard",
                                                               "requestsPerMinute":  999999,
                                                               "maxOutput":  16384
                                                           },
                                                    "gpt-4o-mini-tts":  {
                                                                            "tokensPerMinute":  999999,
                                                                            "outputCost":  0.6,
                                                                            "capabilities":  [
                                                                                                 "code",
                                                                                                 "analysis"
                                                                                             ],
                                                                            "parameterSize":  null,
                                                                            "contextWindow":  128000,
                                                                            "sizeGB":  null,
                                                                            "inputCost":  0.15,
                                                                            "tier":  "lite",
                                                                            "requestsPerMinute":  999999,
                                                                            "maxOutput":  16384
                                                                        },
                                                    "gpt-4-turbo-2024-04-09":  {
                                                                                   "tokensPerMinute":  999999,
                                                                                   "outputCost":  30,
                                                                                   "capabilities":  [
                                                                                                        "vision",
                                                                                                        "code",
                                                                                                        "analysis"
                                                                                                    ],
                                                                                   "parameterSize":  null,
                                                                                   "contextWindow":  128000,
                                                                                   "sizeGB":  null,
                                                                                   "inputCost":  10,
                                                                                   "tier":  "pro",
                                                                                   "requestsPerMinute":  999999,
                                                                                   "maxOutput":  16384
                                                                               },
                                                    "gpt-4o-mini-transcribe-2025-03-20":  {
                                                                                              "tokensPerMinute":  999999,
                                                                                              "outputCost":  0.6,
                                                                                              "capabilities":  [
                                                                                                                   "code",
                                                                                                                   "analysis"
                                                                                                               ],
                                                                                              "parameterSize":  null,
                                                                                              "contextWindow":  128000,
                                                                                              "sizeGB":  null,
                                                                                              "inputCost":  0.15,
                                                                                              "tier":  "lite",
                                                                                              "requestsPerMinute":  999999,
                                                                                              "maxOutput":  16384
                                                                                          },
                                                    "gpt-4o-mini-tts-2025-03-20":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0.6,
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0.15,
                                                                                       "tier":  "lite",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  16384
                                                                                   },
                                                    "gpt-4o-search-preview":  {
                                                                                  "tokensPerMinute":  999999,
                                                                                  "outputCost":  10,
                                                                                  "capabilities":  [
                                                                                                       "vision",
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ],
                                                                                  "parameterSize":  null,
                                                                                  "contextWindow":  128000,
                                                                                  "sizeGB":  null,
                                                                                  "inputCost":  2.5,
                                                                                  "tier":  "pro",
                                                                                  "requestsPerMinute":  999999,
                                                                                  "maxOutput":  16384
                                                                              },
                                                    "gpt-4o":  {
                                                                   "tokensPerMinute":  999999,
                                                                   "outputCost":  10,
                                                                   "capabilities":  [
                                                                                        "vision",
                                                                                        "code",
                                                                                        "analysis"
                                                                                    ],
                                                                   "parameterSize":  null,
                                                                   "contextWindow":  128000,
                                                                   "sizeGB":  null,
                                                                   "inputCost":  2.5,
                                                                   "tier":  "pro",
                                                                   "requestsPerMinute":  999999,
                                                                   "maxOutput":  16384
                                                               },
                                                    "gpt-4.1-mini":  {
                                                                         "tokensPerMinute":  999999,
                                                                         "outputCost":  1.5,
                                                                         "capabilities":  [
                                                                                              "code",
                                                                                              "analysis"
                                                                                          ],
                                                                         "parameterSize":  null,
                                                                         "contextWindow":  128000,
                                                                         "sizeGB":  null,
                                                                         "inputCost":  0.5,
                                                                         "tier":  "standard",
                                                                         "requestsPerMinute":  999999,
                                                                         "maxOutput":  16384
                                                                     },
                                                    "gpt-4":  {
                                                                  "tokensPerMinute":  999999,
                                                                  "outputCost":  1.5,
                                                                  "capabilities":  [
                                                                                       "code",
                                                                                       "analysis"
                                                                                   ],
                                                                  "parameterSize":  null,
                                                                  "contextWindow":  128000,
                                                                  "sizeGB":  null,
                                                                  "inputCost":  0.5,
                                                                  "tier":  "standard",
                                                                  "requestsPerMinute":  999999,
                                                                  "maxOutput":  16384
                                                              },
                                                    "gpt-4o-mini-transcribe":  {
                                                                                   "tokensPerMinute":  999999,
                                                                                   "outputCost":  0.6,
                                                                                   "capabilities":  [
                                                                                                        "code",
                                                                                                        "analysis"
                                                                                                    ],
                                                                                   "parameterSize":  null,
                                                                                   "contextWindow":  128000,
                                                                                   "sizeGB":  null,
                                                                                   "inputCost":  0.15,
                                                                                   "tier":  "lite",
                                                                                   "requestsPerMinute":  999999,
                                                                                   "maxOutput":  16384
                                                                               },
                                                    "o3-mini-2025-01-31":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  4.4,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis",
                                                                                                    "reasoning"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  1.1,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "gpt-4o-mini-search-preview":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0.6,
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0.15,
                                                                                       "tier":  "lite",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  16384
                                                                                   },
                                                    "gpt-4o-2024-05-13":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  10,
                                                                              "capabilities":  [
                                                                                                   "vision",
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  2.5,
                                                                              "tier":  "pro",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          },
                                                    "gpt-4.1-nano":  {
                                                                         "tokensPerMinute":  999999,
                                                                         "outputCost":  1.5,
                                                                         "capabilities":  [
                                                                                              "code",
                                                                                              "analysis"
                                                                                          ],
                                                                         "parameterSize":  null,
                                                                         "contextWindow":  128000,
                                                                         "sizeGB":  null,
                                                                         "inputCost":  0.5,
                                                                         "tier":  "standard",
                                                                         "requestsPerMinute":  999999,
                                                                         "maxOutput":  16384
                                                                     },
                                                    "o1-pro-2025-03-19":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  1.5,
                                                                              "capabilities":  [
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  0.5,
                                                                              "tier":  "standard",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          },
                                                    "gpt-4.1-nano-2025-04-14":  {
                                                                                    "tokensPerMinute":  999999,
                                                                                    "outputCost":  1.5,
                                                                                    "capabilities":  [
                                                                                                         "code",
                                                                                                         "analysis"
                                                                                                     ],
                                                                                    "parameterSize":  null,
                                                                                    "contextWindow":  128000,
                                                                                    "sizeGB":  null,
                                                                                    "inputCost":  0.5,
                                                                                    "tier":  "standard",
                                                                                    "requestsPerMinute":  999999,
                                                                                    "maxOutput":  16384
                                                                                },
                                                    "gpt-4-0613":  {
                                                                       "tokensPerMinute":  999999,
                                                                       "outputCost":  1.5,
                                                                       "capabilities":  [
                                                                                            "code",
                                                                                            "analysis"
                                                                                        ],
                                                                       "parameterSize":  null,
                                                                       "contextWindow":  128000,
                                                                       "sizeGB":  null,
                                                                       "inputCost":  0.5,
                                                                       "tier":  "standard",
                                                                       "requestsPerMinute":  999999,
                                                                       "maxOutput":  16384
                                                                   },
                                                    "o1":  {
                                                               "tokensPerMinute":  999999,
                                                               "outputCost":  1.5,
                                                               "capabilities":  [
                                                                                    "code",
                                                                                    "analysis"
                                                                                ],
                                                               "parameterSize":  null,
                                                               "contextWindow":  128000,
                                                               "sizeGB":  null,
                                                               "inputCost":  0.5,
                                                               "tier":  "standard",
                                                               "requestsPerMinute":  999999,
                                                               "maxOutput":  16384
                                                           },
                                                    "o1-pro":  {
                                                                   "tokensPerMinute":  999999,
                                                                   "outputCost":  1.5,
                                                                   "capabilities":  [
                                                                                        "code",
                                                                                        "analysis"
                                                                                    ],
                                                                   "parameterSize":  null,
                                                                   "contextWindow":  128000,
                                                                   "sizeGB":  null,
                                                                   "inputCost":  0.5,
                                                                   "tier":  "standard",
                                                                   "requestsPerMinute":  999999,
                                                                   "maxOutput":  16384
                                                               },
                                                    "o1-2024-12-17":  {
                                                                          "tokensPerMinute":  999999,
                                                                          "outputCost":  1.5,
                                                                          "capabilities":  [
                                                                                               "code",
                                                                                               "analysis"
                                                                                           ],
                                                                          "parameterSize":  null,
                                                                          "contextWindow":  128000,
                                                                          "sizeGB":  null,
                                                                          "inputCost":  0.5,
                                                                          "tier":  "standard",
                                                                          "requestsPerMinute":  999999,
                                                                          "maxOutput":  16384
                                                                      },
                                                    "gpt-4-1106-preview":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  1.5,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0.5,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "gpt-4-turbo":  {
                                                                        "tokensPerMinute":  999999,
                                                                        "outputCost":  30,
                                                                        "capabilities":  [
                                                                                             "vision",
                                                                                             "code",
                                                                                             "analysis"
                                                                                         ],
                                                                        "parameterSize":  null,
                                                                        "contextWindow":  128000,
                                                                        "sizeGB":  null,
                                                                        "inputCost":  10,
                                                                        "tier":  "pro",
                                                                        "requestsPerMinute":  999999,
                                                                        "maxOutput":  16384
                                                                    },
                                                    "gpt-4o-2024-11-20":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  10,
                                                                              "capabilities":  [
                                                                                                   "vision",
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  2.5,
                                                                              "tier":  "pro",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          },
                                                    "gpt-3.5-turbo-0125":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  1.5,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0.5,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "o3-mini":  {
                                                                    "tokensPerMinute":  999999,
                                                                    "outputCost":  4.4,
                                                                    "capabilities":  [
                                                                                         "code",
                                                                                         "analysis",
                                                                                         "reasoning"
                                                                                     ],
                                                                    "parameterSize":  null,
                                                                    "contextWindow":  128000,
                                                                    "sizeGB":  null,
                                                                    "inputCost":  1.1,
                                                                    "tier":  "standard",
                                                                    "requestsPerMinute":  999999,
                                                                    "maxOutput":  16384
                                                                },
                                                    "gpt-4o-2024-08-06":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  10,
                                                                              "capabilities":  [
                                                                                                   "vision",
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  2.5,
                                                                              "tier":  "pro",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          },
                                                    "gpt-3.5-turbo":  {
                                                                          "tokensPerMinute":  999999,
                                                                          "outputCost":  1.5,
                                                                          "capabilities":  [
                                                                                               "code",
                                                                                               "analysis"
                                                                                           ],
                                                                          "parameterSize":  null,
                                                                          "contextWindow":  128000,
                                                                          "sizeGB":  null,
                                                                          "inputCost":  0.5,
                                                                          "tier":  "standard",
                                                                          "requestsPerMinute":  999999,
                                                                          "maxOutput":  16384
                                                                      },
                                                    "gpt-4o-mini-2024-07-18":  {
                                                                                   "tokensPerMinute":  999999,
                                                                                   "outputCost":  0.6,
                                                                                   "capabilities":  [
                                                                                                        "code",
                                                                                                        "analysis"
                                                                                                    ],
                                                                                   "parameterSize":  null,
                                                                                   "contextWindow":  128000,
                                                                                   "sizeGB":  null,
                                                                                   "inputCost":  0.15,
                                                                                   "tier":  "lite",
                                                                                   "requestsPerMinute":  999999,
                                                                                   "maxOutput":  16384
                                                                               },
                                                    "gpt-3.5-turbo-1106":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  1.5,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0.5,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "gpt-4.1-mini-2025-04-14":  {
                                                                                    "tokensPerMinute":  999999,
                                                                                    "outputCost":  1.5,
                                                                                    "capabilities":  [
                                                                                                         "code",
                                                                                                         "analysis"
                                                                                                     ],
                                                                                    "parameterSize":  null,
                                                                                    "contextWindow":  128000,
                                                                                    "sizeGB":  null,
                                                                                    "inputCost":  0.5,
                                                                                    "tier":  "standard",
                                                                                    "requestsPerMinute":  999999,
                                                                                    "maxOutput":  16384
                                                                                },
                                                    "gpt-4.1-2025-04-14":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  1.5,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0.5,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  16384
                                                                           },
                                                    "gpt-4o-transcribe":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  10,
                                                                              "capabilities":  [
                                                                                                   "vision",
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  2.5,
                                                                              "tier":  "pro",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  16384
                                                                          }
                                                }
                                 },
                      "google":  {
                                     "name":  "Google",
                                     "baseUrl":  "https://generativelanguage.googleapis.com/v1beta",
                                     "apiKeyEnv":  "GOOGLE_API_KEY",
                                     "priority":  3,
                                     "enabled":  true,
                                     "models":  {
                                                    "gemini-2.5-flash-preview-tts":  {
                                                                                         "tokensPerMinute":  999999,
                                                                                         "outputCost":  0,
                                                                                         "capabilities":  [
                                                                                                              "vision",
                                                                                                              "code",
                                                                                                              "analysis"
                                                                                                          ],
                                                                                         "parameterSize":  null,
                                                                                         "contextWindow":  128000,
                                                                                         "sizeGB":  null,
                                                                                         "inputCost":  0,
                                                                                         "tier":  "standard",
                                                                                         "requestsPerMinute":  999999,
                                                                                         "maxOutput":  8192
                                                                                     },
                                                    "gemini-2.0-flash-lite-001":  {
                                                                                      "tokensPerMinute":  999999,
                                                                                      "outputCost":  0,
                                                                                      "capabilities":  [
                                                                                                           "vision",
                                                                                                           "code",
                                                                                                           "analysis"
                                                                                                       ],
                                                                                      "parameterSize":  null,
                                                                                      "contextWindow":  128000,
                                                                                      "sizeGB":  null,
                                                                                      "inputCost":  0,
                                                                                      "tier":  "standard",
                                                                                      "requestsPerMinute":  999999,
                                                                                      "maxOutput":  8192
                                                                                  },
                                                    "gemini-2.5-pro-preview-tts":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0,
                                                                                       "capabilities":  [
                                                                                                            "vision",
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0,
                                                                                       "tier":  "pro",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  8192
                                                                                   },
                                                    "gemini-2.0-flash-lite-preview-02-05":  {
                                                                                                "tokensPerMinute":  999999,
                                                                                                "outputCost":  0,
                                                                                                "capabilities":  [
                                                                                                                     "vision",
                                                                                                                     "code",
                                                                                                                     "analysis"
                                                                                                                 ],
                                                                                                "parameterSize":  null,
                                                                                                "contextWindow":  128000,
                                                                                                "sizeGB":  null,
                                                                                                "inputCost":  0,
                                                                                                "tier":  "standard",
                                                                                                "requestsPerMinute":  999999,
                                                                                                "maxOutput":  8192
                                                                                            },
                                                    "gemini-embedding-001":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "vision",
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "standard",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             },
                                                    "gemini-flash-latest":  {
                                                                                "tokensPerMinute":  999999,
                                                                                "outputCost":  0,
                                                                                "capabilities":  [
                                                                                                     "vision",
                                                                                                     "code",
                                                                                                     "analysis"
                                                                                                 ],
                                                                                "parameterSize":  null,
                                                                                "contextWindow":  128000,
                                                                                "sizeGB":  null,
                                                                                "inputCost":  0,
                                                                                "tier":  "standard",
                                                                                "requestsPerMinute":  999999,
                                                                                "maxOutput":  8192
                                                                            },
                                                    "gemini-2.5-flash":  {
                                                                             "tokensPerMinute":  999999,
                                                                             "outputCost":  0,
                                                                             "capabilities":  [
                                                                                                  "vision",
                                                                                                  "code",
                                                                                                  "analysis"
                                                                                              ],
                                                                             "parameterSize":  null,
                                                                             "contextWindow":  128000,
                                                                             "sizeGB":  null,
                                                                             "inputCost":  0,
                                                                             "tier":  "standard",
                                                                             "requestsPerMinute":  999999,
                                                                             "maxOutput":  8192
                                                                         },
                                                    "gemini-3-flash-preview":  {
                                                                                   "tokensPerMinute":  999999,
                                                                                   "outputCost":  0,
                                                                                   "capabilities":  [
                                                                                                        "vision",
                                                                                                        "code",
                                                                                                        "analysis"
                                                                                                    ],
                                                                                   "parameterSize":  null,
                                                                                   "contextWindow":  128000,
                                                                                   "sizeGB":  null,
                                                                                   "inputCost":  0,
                                                                                   "tier":  "standard",
                                                                                   "requestsPerMinute":  999999,
                                                                                   "maxOutput":  8192
                                                                               },
                                                    "gemini-2.5-flash-lite":  {
                                                                                  "tokensPerMinute":  999999,
                                                                                  "outputCost":  0,
                                                                                  "capabilities":  [
                                                                                                       "vision",
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ],
                                                                                  "parameterSize":  null,
                                                                                  "contextWindow":  128000,
                                                                                  "sizeGB":  null,
                                                                                  "inputCost":  0,
                                                                                  "tier":  "standard",
                                                                                  "requestsPerMinute":  999999,
                                                                                  "maxOutput":  8192
                                                                              },
                                                    "gemini-pro-latest":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  0,
                                                                              "capabilities":  [
                                                                                                   "vision",
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  0,
                                                                              "tier":  "pro",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  8192
                                                                          },
                                                    "gemini-2.5-computer-use-preview-10-2025":  {
                                                                                                    "tokensPerMinute":  999999,
                                                                                                    "outputCost":  0,
                                                                                                    "capabilities":  [
                                                                                                                         "vision",
                                                                                                                         "code",
                                                                                                                         "analysis"
                                                                                                                     ],
                                                                                                    "parameterSize":  null,
                                                                                                    "contextWindow":  128000,
                                                                                                    "sizeGB":  null,
                                                                                                    "inputCost":  0,
                                                                                                    "tier":  "standard",
                                                                                                    "requestsPerMinute":  999999,
                                                                                                    "maxOutput":  8192
                                                                                                },
                                                    "gemini-2.5-flash-preview-09-2025":  {
                                                                                             "tokensPerMinute":  999999,
                                                                                             "outputCost":  0,
                                                                                             "capabilities":  [
                                                                                                                  "vision",
                                                                                                                  "code",
                                                                                                                  "analysis"
                                                                                                              ],
                                                                                             "parameterSize":  null,
                                                                                             "contextWindow":  128000,
                                                                                             "sizeGB":  null,
                                                                                             "inputCost":  0,
                                                                                             "tier":  "standard",
                                                                                             "requestsPerMinute":  999999,
                                                                                             "maxOutput":  8192
                                                                                         },
                                                    "gemini-3-pro-image-preview":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0,
                                                                                       "capabilities":  [
                                                                                                            "vision",
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0,
                                                                                       "tier":  "pro",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  8192
                                                                                   },
                                                    "gemini-2.0-flash":  {
                                                                             "tokensPerMinute":  999999,
                                                                             "outputCost":  0,
                                                                             "capabilities":  [
                                                                                                  "vision",
                                                                                                  "code",
                                                                                                  "analysis"
                                                                                              ],
                                                                             "parameterSize":  null,
                                                                             "contextWindow":  128000,
                                                                             "sizeGB":  null,
                                                                             "inputCost":  0,
                                                                             "tier":  "standard",
                                                                             "requestsPerMinute":  999999,
                                                                             "maxOutput":  8192
                                                                         },
                                                    "gemini-2.5-flash-image-preview":  {
                                                                                           "tokensPerMinute":  999999,
                                                                                           "outputCost":  0,
                                                                                           "capabilities":  [
                                                                                                                "vision",
                                                                                                                "code",
                                                                                                                "analysis"
                                                                                                            ],
                                                                                           "parameterSize":  null,
                                                                                           "contextWindow":  128000,
                                                                                           "sizeGB":  null,
                                                                                           "inputCost":  0,
                                                                                           "tier":  "standard",
                                                                                           "requestsPerMinute":  999999,
                                                                                           "maxOutput":  8192
                                                                                       },
                                                    "gemini-2.5-pro":  {
                                                                           "tokensPerMinute":  999999,
                                                                           "outputCost":  0,
                                                                           "capabilities":  [
                                                                                                "vision",
                                                                                                "code",
                                                                                                "analysis"
                                                                                            ],
                                                                           "parameterSize":  null,
                                                                           "contextWindow":  128000,
                                                                           "sizeGB":  null,
                                                                           "inputCost":  0,
                                                                           "tier":  "pro",
                                                                           "requestsPerMinute":  999999,
                                                                           "maxOutput":  8192
                                                                       },
                                                    "gemini-flash-lite-latest":  {
                                                                                     "tokensPerMinute":  999999,
                                                                                     "outputCost":  0,
                                                                                     "capabilities":  [
                                                                                                          "vision",
                                                                                                          "code",
                                                                                                          "analysis"
                                                                                                      ],
                                                                                     "parameterSize":  null,
                                                                                     "contextWindow":  128000,
                                                                                     "sizeGB":  null,
                                                                                     "inputCost":  0,
                                                                                     "tier":  "standard",
                                                                                     "requestsPerMinute":  999999,
                                                                                     "maxOutput":  8192
                                                                                 },
                                                    "gemini-robotics-er-1.5-preview":  {
                                                                                           "tokensPerMinute":  999999,
                                                                                           "outputCost":  0,
                                                                                           "capabilities":  [
                                                                                                                "vision",
                                                                                                                "code",
                                                                                                                "analysis"
                                                                                                            ],
                                                                                           "parameterSize":  null,
                                                                                           "contextWindow":  128000,
                                                                                           "sizeGB":  null,
                                                                                           "inputCost":  0,
                                                                                           "tier":  "standard",
                                                                                           "requestsPerMinute":  999999,
                                                                                           "maxOutput":  8192
                                                                                       },
                                                    "gemini-2.5-flash-lite-preview-09-2025":  {
                                                                                                  "tokensPerMinute":  999999,
                                                                                                  "outputCost":  0,
                                                                                                  "capabilities":  [
                                                                                                                       "vision",
                                                                                                                       "code",
                                                                                                                       "analysis"
                                                                                                                   ],
                                                                                                  "parameterSize":  null,
                                                                                                  "contextWindow":  128000,
                                                                                                  "sizeGB":  null,
                                                                                                  "inputCost":  0,
                                                                                                  "tier":  "standard",
                                                                                                  "requestsPerMinute":  999999,
                                                                                                  "maxOutput":  8192
                                                                                              },
                                                    "gemini-embedding-exp-03-07":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0,
                                                                                       "capabilities":  [
                                                                                                            "vision",
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0,
                                                                                       "tier":  "standard",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  8192
                                                                                   },
                                                    "gemini-embedding-exp":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "vision",
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "standard",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             },
                                                    "gemini-2.0-flash-lite-preview":  {
                                                                                          "tokensPerMinute":  999999,
                                                                                          "outputCost":  0,
                                                                                          "capabilities":  [
                                                                                                               "vision",
                                                                                                               "code",
                                                                                                               "analysis"
                                                                                                           ],
                                                                                          "parameterSize":  null,
                                                                                          "contextWindow":  128000,
                                                                                          "sizeGB":  null,
                                                                                          "inputCost":  0,
                                                                                          "tier":  "standard",
                                                                                          "requestsPerMinute":  999999,
                                                                                          "maxOutput":  8192
                                                                                      },
                                                    "gemini-3-pro-preview":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "vision",
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "pro",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             },
                                                    "gemini-2.5-flash-image":  {
                                                                                   "tokensPerMinute":  999999,
                                                                                   "outputCost":  0,
                                                                                   "capabilities":  [
                                                                                                        "vision",
                                                                                                        "code",
                                                                                                        "analysis"
                                                                                                    ],
                                                                                   "parameterSize":  null,
                                                                                   "contextWindow":  128000,
                                                                                   "sizeGB":  null,
                                                                                   "inputCost":  0,
                                                                                   "tier":  "standard",
                                                                                   "requestsPerMinute":  999999,
                                                                                   "maxOutput":  8192
                                                                               },
                                                    "gemini-2.0-flash-001":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "vision",
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "standard",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             },
                                                    "gemini-exp-1206":  {
                                                                            "tokensPerMinute":  999999,
                                                                            "outputCost":  0,
                                                                            "capabilities":  [
                                                                                                 "vision",
                                                                                                 "code",
                                                                                                 "analysis"
                                                                                             ],
                                                                            "parameterSize":  null,
                                                                            "contextWindow":  128000,
                                                                            "sizeGB":  null,
                                                                            "inputCost":  0,
                                                                            "tier":  "standard",
                                                                            "requestsPerMinute":  999999,
                                                                            "maxOutput":  8192
                                                                        },
                                                    "gemini-2.0-flash-lite":  {
                                                                                  "tokensPerMinute":  999999,
                                                                                  "outputCost":  0,
                                                                                  "capabilities":  [
                                                                                                       "vision",
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ],
                                                                                  "parameterSize":  null,
                                                                                  "contextWindow":  128000,
                                                                                  "sizeGB":  null,
                                                                                  "inputCost":  0,
                                                                                  "tier":  "standard",
                                                                                  "requestsPerMinute":  999999,
                                                                                  "maxOutput":  8192
                                                                              },
                                                    "gemini-2.0-flash-exp":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "vision",
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "standard",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             }
                                                }
                                 },
                      "mistral":  {
                                      "name":  "Mistral",
                                      "baseUrl":  "https://api.mistral.ai/v1",
                                      "apiKeyEnv":  "MISTRAL_API_KEY",
                                      "priority":  4,
                                      "enabled":  true,
                                      "models":  {
                                                     "mistral-large-latest":  {
                                                                                  "tier":  "pro",
                                                                                  "contextWindow":  128000,
                                                                                  "maxOutput":  8192,
                                                                                  "inputCost":  2.0,
                                                                                  "outputCost":  6.0,
                                                                                  "tokensPerMinute":  60000,
                                                                                  "requestsPerMinute":  60,
                                                                                  "capabilities":  [
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ]
                                                                              },
                                                     "mistral-small-latest":  {
                                                                                  "tier":  "lite",
                                                                                  "contextWindow":  32000,
                                                                                  "maxOutput":  8192,
                                                                                  "inputCost":  0.2,
                                                                                  "outputCost":  0.6,
                                                                                  "tokensPerMinute":  120000,
                                                                                  "requestsPerMinute":  120,
                                                                                  "capabilities":  [
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ]
                                                                              }
                                                 }
                                  },
                      "groq":  {
                                   "name":  "Groq",
                                   "baseUrl":  "https://api.groq.com/openai/v1",
                                   "apiKeyEnv":  "GROQ_API_KEY",
                                   "priority":  5,
                                   "enabled":  true,
                                   "models":  {
                                                  "llama-3.1-8b-instant":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  0,
                                                                               "capabilities":  [
                                                                                                    "code",
                                                                                                    "analysis"
                                                                                                ],
                                                                               "parameterSize":  null,
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  null,
                                                                               "inputCost":  0,
                                                                               "tier":  "standard",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  8192
                                                                           },
                                                  "openai/gpt-oss-120b":  {
                                                                              "tokensPerMinute":  999999,
                                                                              "outputCost":  0,
                                                                              "capabilities":  [
                                                                                                   "code",
                                                                                                   "analysis"
                                                                                               ],
                                                                              "parameterSize":  null,
                                                                              "contextWindow":  128000,
                                                                              "sizeGB":  null,
                                                                              "inputCost":  0,
                                                                              "tier":  "standard",
                                                                              "requestsPerMinute":  999999,
                                                                              "maxOutput":  8192
                                                                          },
                                                  "qwen/qwen3-32b":  {
                                                                         "tokensPerMinute":  999999,
                                                                         "outputCost":  0,
                                                                         "capabilities":  [
                                                                                              "code",
                                                                                              "analysis"
                                                                                          ],
                                                                         "parameterSize":  null,
                                                                         "contextWindow":  128000,
                                                                         "sizeGB":  null,
                                                                         "inputCost":  0,
                                                                         "tier":  "standard",
                                                                         "requestsPerMinute":  999999,
                                                                         "maxOutput":  8192
                                                                     },
                                                  "meta-llama/llama-4-scout-17b-16e-instruct":  {
                                                                                                    "tokensPerMinute":  999999,
                                                                                                    "outputCost":  0,
                                                                                                    "capabilities":  [
                                                                                                                         "code",
                                                                                                                         "analysis"
                                                                                                                     ],
                                                                                                    "parameterSize":  null,
                                                                                                    "contextWindow":  128000,
                                                                                                    "sizeGB":  null,
                                                                                                    "inputCost":  0,
                                                                                                    "tier":  "standard",
                                                                                                    "requestsPerMinute":  999999,
                                                                                                    "maxOutput":  8192
                                                                                                },
                                                  "openai/gpt-oss-20b":  {
                                                                             "tokensPerMinute":  999999,
                                                                             "outputCost":  0,
                                                                             "capabilities":  [
                                                                                                  "code",
                                                                                                  "analysis"
                                                                                              ],
                                                                             "parameterSize":  null,
                                                                             "contextWindow":  128000,
                                                                             "sizeGB":  null,
                                                                             "inputCost":  0,
                                                                             "tier":  "standard",
                                                                             "requestsPerMinute":  999999,
                                                                             "maxOutput":  8192
                                                                         },
                                                  "whisper-large-v3-turbo":  {
                                                                                 "tokensPerMinute":  999999,
                                                                                 "outputCost":  0,
                                                                                 "capabilities":  [
                                                                                                      "code",
                                                                                                      "analysis"
                                                                                                  ],
                                                                                 "parameterSize":  null,
                                                                                 "contextWindow":  128000,
                                                                                 "sizeGB":  null,
                                                                                 "inputCost":  0,
                                                                                 "tier":  "standard",
                                                                                 "requestsPerMinute":  999999,
                                                                                 "maxOutput":  8192
                                                                             },
                                                  "openai/gpt-oss-safeguard-20b":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0,
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0,
                                                                                       "tier":  "standard",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  8192
                                                                                   },
                                                  "meta-llama/llama-prompt-guard-2-86m":  {
                                                                                              "tokensPerMinute":  999999,
                                                                                              "outputCost":  0,
                                                                                              "capabilities":  [
                                                                                                                   "code",
                                                                                                                   "analysis"
                                                                                                               ],
                                                                                              "parameterSize":  null,
                                                                                              "contextWindow":  128000,
                                                                                              "sizeGB":  null,
                                                                                              "inputCost":  0,
                                                                                              "tier":  "standard",
                                                                                              "requestsPerMinute":  999999,
                                                                                              "maxOutput":  8192
                                                                                          },
                                                  "groq/compound":  {
                                                                        "tokensPerMinute":  999999,
                                                                        "outputCost":  0,
                                                                        "capabilities":  [
                                                                                             "code",
                                                                                             "analysis"
                                                                                         ],
                                                                        "parameterSize":  null,
                                                                        "contextWindow":  128000,
                                                                        "sizeGB":  null,
                                                                        "inputCost":  0,
                                                                        "tier":  "standard",
                                                                        "requestsPerMinute":  999999,
                                                                        "maxOutput":  8192
                                                                    },
                                                  "allam-2-7b":  {
                                                                     "tokensPerMinute":  999999,
                                                                     "outputCost":  0,
                                                                     "capabilities":  [
                                                                                          "code",
                                                                                          "analysis"
                                                                                      ],
                                                                     "parameterSize":  null,
                                                                     "contextWindow":  128000,
                                                                     "sizeGB":  null,
                                                                     "inputCost":  0,
                                                                     "tier":  "standard",
                                                                     "requestsPerMinute":  999999,
                                                                     "maxOutput":  8192
                                                                 },
                                                  "meta-llama/llama-prompt-guard-2-22m":  {
                                                                                              "tokensPerMinute":  999999,
                                                                                              "outputCost":  0,
                                                                                              "capabilities":  [
                                                                                                                   "code",
                                                                                                                   "analysis"
                                                                                                               ],
                                                                                              "parameterSize":  null,
                                                                                              "contextWindow":  128000,
                                                                                              "sizeGB":  null,
                                                                                              "inputCost":  0,
                                                                                              "tier":  "standard",
                                                                                              "requestsPerMinute":  999999,
                                                                                              "maxOutput":  8192
                                                                                          },
                                                  "groq/compound-mini":  {
                                                                             "tokensPerMinute":  999999,
                                                                             "outputCost":  0,
                                                                             "capabilities":  [
                                                                                                  "code",
                                                                                                  "analysis"
                                                                                              ],
                                                                             "parameterSize":  null,
                                                                             "contextWindow":  128000,
                                                                             "sizeGB":  null,
                                                                             "inputCost":  0,
                                                                             "tier":  "standard",
                                                                             "requestsPerMinute":  999999,
                                                                             "maxOutput":  8192
                                                                         },
                                                  "canopylabs/orpheus-v1-english":  {
                                                                                        "tokensPerMinute":  999999,
                                                                                        "outputCost":  0,
                                                                                        "capabilities":  [
                                                                                                             "code",
                                                                                                             "analysis"
                                                                                                         ],
                                                                                        "parameterSize":  null,
                                                                                        "contextWindow":  128000,
                                                                                        "sizeGB":  null,
                                                                                        "inputCost":  0,
                                                                                        "tier":  "standard",
                                                                                        "requestsPerMinute":  999999,
                                                                                        "maxOutput":  8192
                                                                                    },
                                                  "canopylabs/orpheus-arabic-saudi":  {
                                                                                          "tokensPerMinute":  999999,
                                                                                          "outputCost":  0,
                                                                                          "capabilities":  [
                                                                                                               "code",
                                                                                                               "analysis"
                                                                                                           ],
                                                                                          "parameterSize":  null,
                                                                                          "contextWindow":  128000,
                                                                                          "sizeGB":  null,
                                                                                          "inputCost":  0,
                                                                                          "tier":  "standard",
                                                                                          "requestsPerMinute":  999999,
                                                                                          "maxOutput":  8192
                                                                                      },
                                                  "moonshotai/kimi-k2-instruct":  {
                                                                                      "tokensPerMinute":  999999,
                                                                                      "outputCost":  0,
                                                                                      "capabilities":  [
                                                                                                           "code",
                                                                                                           "analysis"
                                                                                                       ],
                                                                                      "parameterSize":  null,
                                                                                      "contextWindow":  128000,
                                                                                      "sizeGB":  null,
                                                                                      "inputCost":  0,
                                                                                      "tier":  "standard",
                                                                                      "requestsPerMinute":  999999,
                                                                                      "maxOutput":  8192
                                                                                  },
                                                  "llama-3.3-70b-versatile":  {
                                                                                  "tokensPerMinute":  999999,
                                                                                  "outputCost":  0,
                                                                                  "capabilities":  [
                                                                                                       "code",
                                                                                                       "analysis"
                                                                                                   ],
                                                                                  "parameterSize":  null,
                                                                                  "contextWindow":  128000,
                                                                                  "sizeGB":  null,
                                                                                  "inputCost":  0,
                                                                                  "tier":  "pro",
                                                                                  "requestsPerMinute":  999999,
                                                                                  "maxOutput":  8192
                                                                              },
                                                  "whisper-large-v3":  {
                                                                           "tokensPerMinute":  999999,
                                                                           "outputCost":  0,
                                                                           "capabilities":  [
                                                                                                "code",
                                                                                                "analysis"
                                                                                            ],
                                                                           "parameterSize":  null,
                                                                           "contextWindow":  128000,
                                                                           "sizeGB":  null,
                                                                           "inputCost":  0,
                                                                           "tier":  "standard",
                                                                           "requestsPerMinute":  999999,
                                                                           "maxOutput":  8192
                                                                       },
                                                  "meta-llama/llama-4-maverick-17b-128e-instruct":  {
                                                                                                        "tokensPerMinute":  999999,
                                                                                                        "outputCost":  0,
                                                                                                        "capabilities":  [
                                                                                                                             "code",
                                                                                                                             "analysis"
                                                                                                                         ],
                                                                                                        "parameterSize":  null,
                                                                                                        "contextWindow":  128000,
                                                                                                        "sizeGB":  null,
                                                                                                        "inputCost":  0,
                                                                                                        "tier":  "standard",
                                                                                                        "requestsPerMinute":  999999,
                                                                                                        "maxOutput":  8192
                                                                                                    },
                                                  "meta-llama/llama-guard-4-12b":  {
                                                                                       "tokensPerMinute":  999999,
                                                                                       "outputCost":  0,
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ],
                                                                                       "parameterSize":  null,
                                                                                       "contextWindow":  128000,
                                                                                       "sizeGB":  null,
                                                                                       "inputCost":  0,
                                                                                       "tier":  "standard",
                                                                                       "requestsPerMinute":  999999,
                                                                                       "maxOutput":  8192
                                                                                   },
                                                  "moonshotai/kimi-k2-instruct-0905":  {
                                                                                           "tokensPerMinute":  999999,
                                                                                           "outputCost":  0,
                                                                                           "capabilities":  [
                                                                                                                "code",
                                                                                                                "analysis"
                                                                                                            ],
                                                                                           "parameterSize":  null,
                                                                                           "contextWindow":  128000,
                                                                                           "sizeGB":  null,
                                                                                           "inputCost":  0,
                                                                                           "tier":  "standard",
                                                                                           "requestsPerMinute":  999999,
                                                                                           "maxOutput":  8192
                                                                                       }
                                              }
                               },
                      "ollama":  {
                                     "name":  "Ollama (Local)",
                                     "baseUrl":  "http://localhost:11434/api",
                                     "apiKeyEnv":  null,
                                     "priority":  6,
                                     "enabled":  true,
                                     "models":  {
                                                    "qwen2.5-coder:1.5b":  {
                                                                               "tokensPerMinute":  999999,
                                                                               "outputCost":  0,
                                                                               "capabilities":  [
                                                                                                    "code"
                                                                                                ],
                                                                               "parameterSize":  "1.5B",
                                                                               "contextWindow":  128000,
                                                                               "sizeGB":  0.92,
                                                                               "inputCost":  0,
                                                                               "tier":  "lite",
                                                                               "requestsPerMinute":  999999,
                                                                               "maxOutput":  4096
                                                                           },
                                                    "llama3.2:1b":  {
                                                                        "tokensPerMinute":  999999,
                                                                        "outputCost":  0,
                                                                        "capabilities":  [
                                                                                             "code",
                                                                                             "analysis"
                                                                                         ],
                                                                        "parameterSize":  "1.2B",
                                                                        "contextWindow":  128000,
                                                                        "sizeGB":  1.23,
                                                                        "inputCost":  0,
                                                                        "tier":  "lite",
                                                                        "requestsPerMinute":  999999,
                                                                        "maxOutput":  4096
                                                                    },
                                                    "phi3:mini":  {
                                                                      "tokensPerMinute":  999999,
                                                                      "outputCost":  0,
                                                                      "capabilities":  [
                                                                                           "code",
                                                                                           "analysis"
                                                                                       ],
                                                                      "parameterSize":  "3.8B",
                                                                      "contextWindow":  128000,
                                                                      "sizeGB":  2.03,
                                                                      "inputCost":  0,
                                                                      "tier":  "lite",
                                                                      "requestsPerMinute":  999999,
                                                                      "maxOutput":  4096
                                                                  },
                                                    "llama3.2:3b":  {
                                                                        "tokensPerMinute":  999999,
                                                                        "outputCost":  0,
                                                                        "capabilities":  [
                                                                                             "code",
                                                                                             "analysis"
                                                                                         ],
                                                                        "parameterSize":  "3.2B",
                                                                        "contextWindow":  128000,
                                                                        "sizeGB":  1.88,
                                                                        "inputCost":  0,
                                                                        "tier":  "lite",
                                                                        "requestsPerMinute":  999999,
                                                                        "maxOutput":  4096
                                                                    }
                                                }
                                 }
                  },
    "fallbackChain":  {
                          "anthropic":  [
                                            "claude-opus-4-20250514",
                                            "claude-sonnet-4-20250514",
                                            "claude-3-5-sonnet-20241022",
                                            "claude-3-5-haiku-20241022"
                                        ],
                          "openai":  [
                                         "gpt-4o",
                                         "gpt-4-turbo",
                                         "gpt-4o-mini",
                                         "gpt-3.5-turbo",
                                         "gpt-3.5-turbo-16k",
                                         "gpt-4o-mini-transcribe-2025-12-15",
                                         "gpt-4o-search-preview-2025-03-11",
                                         "gpt-4.1",
                                         "gpt-4-turbo-preview",
                                         "gpt-4o-mini-tts-2025-12-15",
                                         "o3-2025-04-16",
                                         "gpt-4o-mini-search-preview-2025-03-11",
                                         "gpt-4o-transcribe-diarize",
                                         "gpt-4-0125-preview",
                                         "o3",
                                         "gpt-4o-mini-tts",
                                         "gpt-4-turbo-2024-04-09",
                                         "gpt-4o-mini-transcribe-2025-03-20",
                                         "gpt-4o-mini-tts-2025-03-20",
                                         "gpt-4o-search-preview",
                                         "gpt-4.1-mini",
                                         "gpt-4",
                                         "gpt-4o-mini-transcribe",
                                         "o3-mini-2025-01-31",
                                         "gpt-4o-mini-search-preview",
                                         "gpt-4o-2024-05-13",
                                         "gpt-4.1-nano",
                                         "o1-pro-2025-03-19",
                                         "gpt-4.1-nano-2025-04-14",
                                         "gpt-4-0613",
                                         "o1",
                                         "o1-pro",
                                         "o1-2024-12-17",
                                         "gpt-4-1106-preview",
                                         "gpt-4o-2024-11-20",
                                         "gpt-3.5-turbo-0125",
                                         "o3-mini",
                                         "gpt-4o-2024-08-06",
                                         "gpt-4o-mini-2024-07-18",
                                         "gpt-3.5-turbo-1106",
                                         "gpt-4.1-mini-2025-04-14",
                                         "gpt-4.1-2025-04-14",
                                         "gpt-4o-transcribe"
                                     ],
                          "google":  [
                                         "gemini-2.5-pro",
                                         "gemini-2.5-flash",
                                         "gemini-2.0-flash",
                                         "gemini-2.0-flash-lite",
                                         "gemini-2.5-flash-preview-tts",
                                         "gemini-2.0-flash-lite-001",
                                         "gemini-2.5-pro-preview-tts",
                                         "gemini-2.0-flash-lite-preview-02-05",
                                         "gemini-embedding-001",
                                         "gemini-flash-latest",
                                         "gemini-3-flash-preview",
                                         "gemini-2.5-flash-lite",
                                         "gemini-pro-latest",
                                         "gemini-2.5-computer-use-preview-10-2025",
                                         "gemini-2.5-flash-preview-09-2025",
                                         "gemini-3-pro-image-preview",
                                         "gemini-2.5-flash-image-preview",
                                         "gemini-flash-lite-latest",
                                         "gemini-robotics-er-1.5-preview",
                                         "gemini-2.5-flash-lite-preview-09-2025",
                                         "gemini-embedding-exp-03-07",
                                         "gemini-embedding-exp",
                                         "gemini-2.0-flash-lite-preview",
                                         "gemini-3-pro-preview",
                                         "gemini-2.5-flash-image",
                                         "gemini-2.0-flash-001",
                                         "gemini-exp-1206",
                                         "gemini-2.0-flash-exp"
                                     ],
                          "mistral":  [
                                          "mistral-large-latest",
                                          "mistral-small-latest"
                                      ],
                          "groq":  [
                                       "llama-3.3-70b-versatile",
                                       "llama-3.1-8b-instant",
                                       "whisper-large-v3",
                                       "qwen/qwen3-32b",
                                       "openai/gpt-oss-120b",
                                       "openai/gpt-oss-20b",
                                       "whisper-large-v3-turbo",
                                       "openai/gpt-oss-safeguard-20b",
                                       "meta-llama/llama-prompt-guard-2-86m",
                                       "groq/compound",
                                       "meta-llama/llama-4-scout-17b-16e-instruct",
                                       "allam-2-7b",
                                       "meta-llama/llama-prompt-guard-2-22m",
                                       "groq/compound-mini",
                                       "canopylabs/orpheus-v1-english",
                                       "canopylabs/orpheus-arabic-saudi",
                                       "moonshotai/kimi-k2-instruct",
                                       "meta-llama/llama-4-maverick-17b-128e-instruct",
                                       "meta-llama/llama-guard-4-12b",
                                       "moonshotai/kimi-k2-instruct-0905"
                                   ],
                          "ollama":  [
                                         "llama3.2:3b",
                                         "phi3:mini",
                                         "qwen2.5-coder:1.5b",
                                         "llama3.2:1b"
                                     ]
                      },
    "providerFallbackOrder":  [
                                  "anthropic",
                                  "openai",
                                  "google",
                                  "mistral",
                                  "groq",
                                  "ollama"
                              ],
    "settings":  {
                     "costOptimization":  true,
                     "ollamaDefaultModel":  "llama3.2:3b",
                     "autoInstallOllama":  true,
                     "maxRetries":  3,
                     "autoFallback":  true,
                     "logLevel":  "info",
                     "logFormat":  "json",
                     "preferLocal":  true,
                     "rateLimitThreshold":  0.85,
                     "streamResponses":  true,
                     "outputTokenRatio":  0.5,
                     "parallelExecution":  {
                                               "maxConcurrent":  4,
                                               "batchSize":  10,
                                               "timeoutMs":  30000,
                                               "enabled":  true
                                           },
                     "retryDelayMs":  1000,
                     "modelDiscovery":  {
                                            "enabled":  true,
                                            "updateConfigOnStart":  true,
                                            "parallel":  true,
                                            "skipValidation":  false
                                        },
                     "advancedAI":  {
                                        "selfCorrection":  {
                                                               "enabled":  true,
                                                               "validationModel":  "phi3:mini",
                                                               "maxAttempts":  3
                                                           },
                                        "fewShotLearning":  {
                                                                "enabled":  true,
                                                                "maxExamples":  3,
                                                                "maxHistoryEntries":  100
                                                            },
                                        "speculativeDecoding":  {
                                                                    "enabled":  true,
                                                                    "fastModel":  "llama3.2:1b",
                                                                    "accurateModel":  "llama3.2:3b",
                                                                    "codeModel":  "qwen2.5-coder:1.5b",
                                                                    "timeoutMs":  30000
                                                                },
                                        "promptOptimizer":  {
                                                                "enabled":  true,
                                                                "autoOptimize":  true,
                                                                "minClarityThreshold":  60,
                                                                "showEnhancements":  true
                                                            }
                                    }
                 },
    "discovery":  {
                      "summary":  {
                                      "ollama":  {
                                                     "Error":  null,
                                                     "Success":  true,
                                                     "ModelCount":  4
                                                 },
                                      "mistral":  {
                                                      "Error":  "API key not configured",
                                                      "Success":  false,
                                                      "ModelCount":  0
                                                  },
                                      "anthropic":  {
                                                        "Error":  null,
                                                        "Success":  true,
                                                        "ModelCount":  4
                                                    },
                                      "google":  {
                                                     "Error":  null,
                                                     "Success":  true,
                                                     "ModelCount":  28
                                                 },
                                      "openai":  {
                                                     "Error":  null,
                                                     "Success":  true,
                                                     "ModelCount":  43
                                                 },
                                      "groq":  {
                                                   "Error":  null,
                                                   "Success":  true,
                                                   "ModelCount":  20
                                               }
                                  },
                      "totalModels":  99,
                      "fetchDurationMs":  1991,
                      "lastFetch":  "2026-01-14T06:08:34.5625230+01:00"
                  },
    "pipeline":  {
                     "name":  "AI Handler Pipeline",
                     "version":  "1.0.0",
                     "description":  "Complete AI model management system with local-first execution, parallel processing, and multi-provider fallback",
                     "author":  "HYDRA System",
                     "created":  "2025-01-12",
                     "architecture":  {
                                          "core_module":  {
                                                              "path":  "ai-handler/AIModelHandler.psm1",
                                                              "description":  "Main PowerShell module with all AI handling functions",
                                                              "exported_functions":  [
                                                                                         "Get-AIConfig",
                                                                                         "Save-AIConfig",
                                                                                         "Initialize-AIState",
                                                                                         "Get-OptimalModel",
                                                                                         "Get-FallbackModel",
                                                                                         "Get-RateLimitStatus",
                                                                                         "Update-UsageTracking",
                                                                                         "Invoke-AIRequest",
                                                                                         "Invoke-AIRequestParallel",
                                                                                         "Invoke-AIBatch",
                                                                                         "Get-LocalModels",
                                                                                         "Get-AIStatus",
                                                                                         "Reset-AIState",
                                                                                         "Test-AIProviders",
                                                                                         "Test-OllamaAvailable",
                                                                                         "Install-OllamaAuto"
                                                                                     ]
                                                          },
                                          "config_file":  {
                                                              "path":  "ai-handler/ai-config.json",
                                                              "description":  "JSON configuration for providers, models, and settings"
                                                          },
                                          "launcher_integration":  {
                                                                       "path":  "_launcher.ps1",
                                                                       "description":  "Main launcher with AI Handler auto-initialization"
                                                                   }
                                      },
                     "providers":  {
                                       "ollama":  {
                                                      "priority":  1,
                                                      "type":  "local",
                                                      "cost":  0.00,
                                                      "base_url":  "http://localhost:11434/api",
                                                      "requires_api_key":  false,
                                                      "auto_install":  true,
                                                      "models":  {
                                                                     "llama3.2:3b":  {
                                                                                         "tier":  "standard",
                                                                                         "size_gb":  2.0,
                                                                                         "context_window":  128000,
                                                                                         "use_case":  "default_general_purpose",
                                                                                         "capabilities":  [
                                                                                                              "code",
                                                                                                              "analysis",
                                                                                                              "creative"
                                                                                                          ]
                                                                                     },
                                                                     "qwen2.5-coder:1.5b":  {
                                                                                                "tier":  "lite",
                                                                                                "size_gb":  0.9,
                                                                                                "context_window":  32768,
                                                                                                "use_case":  "code_generation",
                                                                                                "capabilities":  [
                                                                                                                     "code"
                                                                                                                 ]
                                                                                            },
                                                                     "phi3:mini":  {
                                                                                       "tier":  "lite",
                                                                                       "size_gb":  2.2,
                                                                                       "context_window":  128000,
                                                                                       "use_case":  "reasoning",
                                                                                       "capabilities":  [
                                                                                                            "code",
                                                                                                            "analysis"
                                                                                                        ]
                                                                                   },
                                                                     "llama3.2:1b":  {
                                                                                         "tier":  "lite",
                                                                                         "size_gb":  1.3,
                                                                                         "context_window":  128000,
                                                                                         "use_case":  "fast_responses",
                                                                                         "capabilities":  [
                                                                                                              "code",
                                                                                                              "analysis"
                                                                                                          ]
                                                                                     }
                                                                 }
                                                  },
                                       "openai":  {
                                                      "priority":  2,
                                                      "type":  "cloud",
                                                      "base_url":  "https://api.openai.com/v1",
                                                      "requires_api_key":  true,
                                                      "api_key_env":  "OPENAI_API_KEY",
                                                      "models":  {
                                                                     "gpt-4o":  {
                                                                                    "tier":  "pro",
                                                                                    "cost_per_1k":  {
                                                                                                        "input":  2.50,
                                                                                                        "output":  10.00
                                                                                                    },
                                                                                    "context_window":  128000,
                                                                                    "use_case":  "high_quality_cloud"
                                                                                },
                                                                     "gpt-4o-mini":  {
                                                                                         "tier":  "lite",
                                                                                         "cost_per_1k":  {
                                                                                                             "input":  0.15,
                                                                                                             "output":  0.60
                                                                                                         },
                                                                                         "context_window":  128000,
                                                                                         "use_case":  "cheap_cloud_fallback"
                                                                                     }
                                                                 }
                                                  },
                                       "anthropic":  {
                                                         "priority":  3,
                                                         "type":  "cloud",
                                                         "base_url":  "https://api.anthropic.com/v1",
                                                         "requires_api_key":  true,
                                                         "api_key_env":  "ANTHROPIC_API_KEY",
                                                         "models":  {
                                                                        "claude-sonnet-4-20250514":  {
                                                                                                         "tier":  "pro",
                                                                                                         "cost_per_1k":  {
                                                                                                                             "input":  3.00,
                                                                                                                             "output":  15.00
                                                                                                                         },
                                                                                                         "context_window":  200000,
                                                                                                         "use_case":  "highest_quality"
                                                                                                     },
                                                                        "claude-3-5-haiku-20241022":  {
                                                                                                          "tier":  "lite",
                                                                                                          "cost_per_1k":  {
                                                                                                                              "input":  0.80,
                                                                                                                              "output":  4.00
                                                                                                                          },
                                                                                                          "context_window":  200000,
                                                                                                          "use_case":  "balanced_cloud"
                                                                                                      }
                                                                    }
                                                     }
                                   },
                     "decision_matrix":  {
                                             "description":  "Rules for selecting provider and model",
                                             "rules":  [
                                                           {
                                                               "id":  1,
                                                               "name":  "check_ollama_first",
                                                               "condition":  "ANY request",
                                                               "action":  "Test-OllamaAvailable before cloud API",
                                                               "priority":  "critical"
                                                           },
                                                           {
                                                               "id":  2,
                                                               "name":  "prefer_local",
                                                               "condition":  "settings.preferLocal == true AND Ollama available",
                                                               "action":  "Use ollama provider",
                                                               "priority":  "high"
                                                           },
                                                           {
                                                               "id":  3,
                                                               "name":  "parallel_for_batch",
                                                               "condition":  "Multiple independent prompts",
                                                               "action":  "Use Invoke-AIBatch with runspace pool",
                                                               "priority":  "high"
                                                           },
                                                           {
                                                               "id":  4,
                                                               "name":  "code_specialist",
                                                               "condition":  "Query matches code patterns",
                                                               "action":  "Use qwen2.5-coder:1.5b",
                                                               "priority":  "medium"
                                                           },
                                                           {
                                                               "id":  5,
                                                               "name":  "fast_mode",
                                                               "condition":  "User requests -Fast OR simple query",
                                                               "action":  "Use llama3.2:1b",
                                                               "priority":  "medium"
                                                           },
                                                           {
                                                               "id":  6,
                                                               "name":  "cloud_fallback",
                                                               "condition":  "Ollama unavailable OR quality insufficient",
                                                               "action":  "Fallback to openai/anthropic",
                                                               "priority":  "low"
                                                           }
                                                       ],
                                             "code_detection_patterns":  [
                                                                             "write.*(function|code|script|class|method)",
                                                                             "create.*(function|code|script|class|method)",
                                                                             "implement\\s+",
                                                                             "fix.*(bug|error|code)",
                                                                             "\\b(regex|regexp)\\b",
                                                                             "\\b(sql|query)\\s+(to|for|that)",
                                                                             "\\bapi\\s+(endpoint|call|request)",
                                                                             "in\\s+(python|javascript|powershell|bash|rust|go|java|c#|typescript)"
                                                                         ],
                                             "model_selection_flow":  {
                                                                          "start":  "receive_request",
                                                                          "steps":  [
                                                                                        {
                                                                                            "step":  1,
                                                                                            "action":  "check_ollama_available",
                                                                                            "true":  "step_2",
                                                                                            "false":  "use_cloud_provider"
                                                                                        },
                                                                                        {
                                                                                            "step":  2,
                                                                                            "action":  "check_if_batch_request",
                                                                                            "true":  "use_parallel_execution",
                                                                                            "false":  "step_3"
                                                                                        },
                                                                                        {
                                                                                            "step":  3,
                                                                                            "action":  "check_code_patterns",
                                                                                            "true":  "use_qwen_coder",
                                                                                            "false":  "step_4"
                                                                                        },
                                                                                        {
                                                                                            "step":  4,
                                                                                            "action":  "check_fast_flag",
                                                                                            "true":  "use_llama_1b",
                                                                                            "false":  "use_llama_3b"
                                                                                        }
                                                                                    ]
                                                                      }
                                         },
                     "fallback_chains":  {
                                             "ollama":  [
                                                            "llama3.2:3b",
                                                            "qwen2.5-coder:1.5b",
                                                            "phi3:mini",
                                                            "llama3.2:1b"
                                                        ],
                                             "openai":  [
                                                            "gpt-4o",
                                                            "gpt-4o-mini"
                                                        ],
                                             "anthropic":  [
                                                               "claude-sonnet-4-20250514",
                                                               "claude-3-5-sonnet-20241022",
                                                               "claude-3-5-haiku-20241022"
                                                           ],
                                             "cross_provider":  [
                                                                    "ollama",
                                                                    "openai",
                                                                    "anthropic"
                                                                ]
                                         },
                     "parallel_execution":  {
                                                "engine":  "PowerShell Runspace Pool",
                                                "implementation":  {
                                                                       "method":  "InitialSessionState with pre-loaded module",
                                                                       "max_concurrent":  4,
                                                                       "timeout_ms":  30000,
                                                                       "batch_size":  10
                                                                   },
                                                "workflow":  [
                                                                 "Create InitialSessionState",
                                                                 "Import AIModelHandler module into ISS",
                                                                 "Create RunspacePool with ISS",
                                                                 "Create PowerShell instance per request",
                                                                 "BeginInvoke all requests",
                                                                 "Collect results with timeout",
                                                                 "Dispose runspaces"
                                                             ],
                                                "performance":  {
                                                                    "4_requests":  "~2s parallel vs ~12s sequential",
                                                                    "speedup_factor":  "4-6x",
                                                                    "cpu_utilization_target":  "\u003e80%"
                                                                }
                                            },
                     "commands":  {
                                      "/ai":  {
                                                  "script":  "Invoke-QuickAI.ps1",
                                                  "description":  "Single local AI query",
                                                  "flags":  [
                                                                "-Code",
                                                                "-Fast",
                                                                "-MaxTokens"
                                                            ],
                                                  "auto_detection":  true,
                                                  "default_model":  "llama3.2:3b",
                                                  "examples":  [
                                                                   "/ai What is 2+2?",
                                                                   "/ai -Code Write a Python function",
                                                                   "/ai -Fast Quick answer please"
                                                               ]
                                              },
                                      "/ai-batch":  {
                                                        "script":  "Invoke-QuickAIBatch.ps1",
                                                        "description":  "Multiple parallel queries",
                                                        "flags":  [
                                                                      "-File",
                                                                      "-Model",
                                                                      "-MaxConcurrent",
                                                                      "-MaxTokens"
                                                                  ],
                                                        "input_format":  "semicolon_separated OR file",
                                                        "examples":  [
                                                                         "/ai-batch \"Q1; Q2; Q3; Q4\"",
                                                                         "/ai-batch -File queries.txt"
                                                                     ]
                                                    },
                                      "/ai-status":  {
                                                         "script":  "Invoke-AIStatus.ps1",
                                                         "description":  "Provider and model status",
                                                         "flags":  [
                                                                       "-Test"
                                                                   ],
                                                         "shows":  [
                                                                       "provider_status",
                                                                       "local_models",
                                                                       "configuration",
                                                                       "fallback_chain",
                                                                       "connectivity_test",
                                                                       "cost_summary"
                                                                   ]
                                                     },
                                      "/ai-config":  {
                                                         "script":  "Invoke-AIConfig.ps1",
                                                         "description":  "Configuration management",
                                                         "flags":  [
                                                                       "-Show",
                                                                       "-PreferLocal",
                                                                       "-AutoFallback",
                                                                       "-CostOptimization",
                                                                       "-DefaultModel",
                                                                       "-MaxConcurrent",
                                                                       "-Timeout",
                                                                       "-Priority",
                                                                       "-Reset"
                                                                   ],
                                                         "examples":  [
                                                                          "/ai-config -Show",
                                                                          "/ai-config -PreferLocal true",
                                                                          "/ai-config -MaxConcurrent 8",
                                                                          "/ai-config -Priority \"anthropic,openai,ollama\""
                                                                      ]
                                                     },
                                      "/ai-pull":  {
                                                       "script":  "Invoke-AIPull.ps1",
                                                       "description":  "Ollama model management",
                                                       "flags":  [
                                                                     "-List",
                                                                     "-Popular",
                                                                     "-Remove"
                                                                 ],
                                                       "examples":  [
                                                                        "/ai-pull -List",
                                                                        "/ai-pull -Popular",
                                                                        "/ai-pull mistral:7b",
                                                                        "/ai-pull -Remove phi3:mini"
                                                                    ]
                                                   },
                                      "/ai-help":  {
                                                       "script":  "Invoke-AIHelp.ps1",
                                                       "description":  "Command reference"
                                                   }
                                  },
                     "launcher_integration":  {
                                                  "steps":  [
                                                                {
                                                                    "step":  1,
                                                                    "name":  "load_ai_handler",
                                                                    "action":  "Import-Module AIModelHandler.psm1 -Force -Global"
                                                                },
                                                                {
                                                                    "step":  2,
                                                                    "name":  "check_ollama",
                                                                    "action":  "Test-OllamaAvailable",
                                                                    "on_fail":  "auto_start_ollama"
                                                                },
                                                                {
                                                                    "step":  3,
                                                                    "name":  "display_status",
                                                                    "action":  "Show providers, models, mode"
                                                                },
                                                                {
                                                                    "step":  4,
                                                                    "name":  "launch_claude",
                                                                    "action":  "Start Claude CLI with AI Handler available"
                                                                }
                                                            ],
                                                  "auto_start_ollama":  {
                                                                            "exe_path":  "$env:LOCALAPPDATA\\Programs\\Ollama\\ollama.exe",
                                                                            "arguments":  "serve",
                                                                            "window_style":  "Hidden",
                                                                            "wait_time_seconds":  3
                                                                        }
                                              },
                     "error_handling":  {
                                            "error_types":  {
                                                                "RateLimit":  {
                                                                                  "pattern":  "rate.?limit|429|too many requests",
                                                                                  "action":  "fallback_to_next_model",
                                                                                  "retry":  true
                                                                              },
                                                                "Overloaded":  {
                                                                                   "pattern":  "overloaded|503|capacity",
                                                                                   "action":  "fallback_to_next_provider",
                                                                                   "retry":  true
                                                                               },
                                                                "AuthError":  {
                                                                                  "pattern":  "401|403|unauthorized|forbidden|invalid.*key",
                                                                                  "action":  "skip_provider",
                                                                                  "retry":  false
                                                                              },
                                                                "ServerError":  {
                                                                                    "pattern":  "500|502|504|server error",
                                                                                    "action":  "retry_with_backoff",
                                                                                    "retry":  true
                                                                                }
                                                            },
                                            "retry_config":  {
                                                                 "max_retries":  3,
                                                                 "retry_delay_ms":  1000,
                                                                 "backoff_multiplier":  2
                                                             }
                                        },
                     "cost_optimization":  {
                                               "strategy":  "local_first_then_cheapest",
                                               "cost_tiers":  {
                                                                  "free":  [
                                                                               "ollama/*"
                                                                           ],
                                                                  "cheap":  [
                                                                                "gpt-4o-mini",
                                                                                "claude-3-5-haiku"
                                                                            ],
                                                                  "standard":  [
                                                                                   "gpt-4o",
                                                                                   "claude-3-5-sonnet"
                                                                               ],
                                                                  "premium":  [
                                                                                  "claude-sonnet-4"
                                                                              ]
                                                              },
                                               "selection_priority":  [
                                                                          "local_available",
                                                                          "lowest_cost",
                                                                          "best_capability_match"
                                                                      ]
                                           },
                     "files_created":  {
                                           "core":  [
                                                        "ai-handler/AIModelHandler.psm1",
                                                        "ai-handler/ai-config.json"
                                                    ],
                                           "commands":  [
                                                            "ai-handler/Invoke-QuickAI.ps1",
                                                            "ai-handler/Invoke-QuickAIBatch.ps1",
                                                            "ai-handler/Invoke-AIStatus.ps1",
                                                            "ai-handler/Invoke-AIHealth.ps1",
                                                            "ai-handler/Invoke-AIConfig.ps1",
                                                            "ai-handler/Invoke-AIPull.ps1",
                                                            "ai-handler/Invoke-AIHelp.ps1"
                                                        ],
                                           "command_definitions":  [
                                                                       ".claude/commands/ai.md",
                                                                       ".claude/commands/ai-batch.md",
                                                                       ".claude/commands/ai-status.md",
                                                                       ".claude/commands/ai-config.md",
                                                                       ".claude/commands/ai-pull.md",
                                                                       ".claude/commands/ai-help.md"
                                                                   ],
                                           "tests":  [
                                                         "ai-handler/test-ollama.ps1",
                                                         "ai-handler/test-fallback.ps1",
                                                         "ai-handler/test-api-failure.ps1",
                                                         "ai-handler/test-parallel.ps1",
                                                         "ai-handler/test-matrix-real.ps1",
                                                         "ai-handler/test-all-ollama.ps1"
                                                     ],
                                           "utilities":  [
                                                             "ai-handler/Install-Ollama.ps1",
                                                             "ai-handler/Initialize-AIHandler.ps1"
                                                         ]
                                       },
                     "integration_points":  {
                                                "claude_md":  {
                                                                  "section":  "10. AI Handler - Matryca Decyzyjna",
                                                                  "content":  "Decision matrix, commands, rules for Claude"
                                                              },
                                                "launcher":  {
                                                                 "file":  "_launcher.ps1",
                                                                 "features":  [
                                                                                  "auto_load_module",
                                                                                  "auto_start_ollama",
                                                                                  "status_display"
                                                                              ]
                                                             }
                                            },
                     "performance_benchmarks":  {
                                                    "single_query":  {
                                                                         "ollama_llama3.2_3b":  "2-5s",
                                                                         "ollama_llama3.2_1b":  "1-2s",
                                                                         "ollama_qwen_coder":  "2-4s",
                                                                         "openai_gpt4o_mini":  "1-2s",
                                                                         "anthropic_haiku":  "0.5-1s"
                                                                     },
                                                    "batch_4_queries":  {
                                                                            "parallel":  "2-5s",
                                                                            "sequential":  "12-20s",
                                                                            "speedup":  "4-6x"
                                                                        }
                                                },
                     "usage_examples":  {
                                            "simple_query":  {
                                                                 "command":  "/ai What is the capital of Poland?",
                                                                 "model_used":  "llama3.2:3b",
                                                                 "cost":  "$0.00"
                                                             },
                                            "code_generation":  {
                                                                    "command":  "/ai Write a Python function to sort a list",
                                                                    "model_used":  "qwen2.5-coder:1.5b (auto-detected)",
                                                                    "cost":  "$0.00"
                                                                },
                                            "batch_analysis":  {
                                                                   "command":  "/ai-batch \"Analyze security; Check performance; Suggest improvements\"",
                                                                   "model_used":  "llama3.2:3b x3 parallel",
                                                                   "cost":  "$0.00",
                                                                   "time":  "~3s"
                                                               },
                                            "cloud_fallback":  {
                                                                   "scenario":  "Ollama not available",
                                                                   "fallback_chain":  "openai/gpt-4o-mini -\u003e anthropic/claude-3-5-haiku",
                                                                   "cost":  "$0.001-0.01"
                                                               }
                                        }
                 },
    "promptOptimizerConfig":  {
                                  "$schema":  "https://json-schema.org/draft/2020-12/schema",
                                  "name":  "PromptOptimizer",
                                  "version":  "1.0.0",
                                  "description":  "Automatic prompt enhancement for GeminiCLI",
                                  "config":  {
                                                 "enabled":  true,
                                                 "autoOptimize":  true,
                                                 "showEnhancements":  false,
                                                 "minClarityThreshold":  60,
                                                 "maxPromptLength":  32000,
                                                 "cacheEnabled":  true,
                                                 "cacheTTLSeconds":  3600
                                             },
                                  "categories":  {
                                                     "code":  {
                                                                  "keywords":  [
                                                                                   "write",
                                                                                   "implement",
                                                                                   "create function",
                                                                                   "code",
                                                                                   "script",
                                                                                   "program",
                                                                                   "fix bug",
                                                                                   "debug",
                                                                                   "refactor",
                                                                                   "class",
                                                                                   "method"
                                                                               ],
                                                                  "enhancers":  [
                                                                                    "Provide clean, well-documented code.",
                                                                                    "Include error handling where appropriate.",
                                                                                    "Follow best practices for the language.",
                                                                                    "Add type hints/annotations if applicable."
                                                                                ],
                                                                  "systemPrompt":  "You are an expert programmer. Write clean, efficient, and well-documented code.",
                                                                  "temperature":  0.3,
                                                                  "topP":  0.9
                                                              },
                                                     "analysis":  {
                                                                      "keywords":  [
                                                                                       "analyze",
                                                                                       "compare",
                                                                                       "explain",
                                                                                       "evaluate",
                                                                                       "assess",
                                                                                       "review",
                                                                                       "examine",
                                                                                       "investigate"
                                                                                   ],
                                                                      "enhancers":  [
                                                                                        "Provide a structured analysis.",
                                                                                        "Consider multiple perspectives.",
                                                                                        "Support conclusions with reasoning.",
                                                                                        "Use clear headings and sections."
                                                                                    ],
                                                                      "systemPrompt":  "You are an analytical expert. Provide thorough, balanced analysis with clear reasoning.",
                                                                      "temperature":  0.5,
                                                                      "topP":  0.95
                                                                  },
                                                     "question":  {
                                                                      "keywords":  [
                                                                                       "what is",
                                                                                       "how does",
                                                                                       "why",
                                                                                       "when",
                                                                                       "where",
                                                                                       "who",
                                                                                       "which",
                                                                                       "?",
                                                                                       "explain"
                                                                                   ],
                                                                      "enhancers":  [
                                                                                        "Be concise but thorough.",
                                                                                        "Provide examples if helpful.",
                                                                                        "Start with a direct answer."
                                                                                    ],
                                                                      "systemPrompt":  "Provide clear, accurate, and helpful answers.",
                                                                      "temperature":  0.4,
                                                                      "topP":  0.9
                                                                  },
                                                     "creative":  {
                                                                      "keywords":  [
                                                                                       "write story",
                                                                                       "generate",
                                                                                       "brainstorm",
                                                                                       "imagine",
                                                                                       "creative",
                                                                                       "ideas",
                                                                                       "invent"
                                                                                   ],
                                                                      "enhancers":  [
                                                                                        "Be creative and original.",
                                                                                        "Explore unique angles.",
                                                                                        "Think outside the box."
                                                                                    ],
                                                                      "systemPrompt":  "You are a creative writer. Be imaginative and original.",
                                                                      "temperature":  0.9,
                                                                      "topP":  0.98
                                                                  },
                                                     "task":  {
                                                                  "keywords":  [
                                                                                   "do",
                                                                                   "execute",
                                                                                   "run",
                                                                                   "perform",
                                                                                   "make",
                                                                                   "build",
                                                                                   "setup",
                                                                                   "configure",
                                                                                   "install"
                                                                               ],
                                                                  "enhancers":  [
                                                                                    "Provide step-by-step instructions.",
                                                                                    "Include verification steps.",
                                                                                    "Mention prerequisites if any."
                                                                                ],
                                                                  "systemPrompt":  "Provide clear, actionable instructions.",
                                                                  "temperature":  0.3,
                                                                  "topP":  0.9
                                                              },
                                                     "summary":  {
                                                                     "keywords":  [
                                                                                      "summarize",
                                                                                      "summary",
                                                                                      "brief",
                                                                                      "tldr",
                                                                                      "overview",
                                                                                      "recap",
                                                                                      "condense"
                                                                                  ],
                                                                     "enhancers":  [
                                                                                       "Be concise - focus on key points.",
                                                                                       "Use bullet points for clarity.",
                                                                                       "Prioritize most important information."
                                                                                   ],
                                                                     "systemPrompt":  "Provide concise, well-organized summaries.",
                                                                     "temperature":  0.3,
                                                                     "topP":  0.85
                                                                 }
                                                 },
                                  "languageDetection":  {
                                                            "python":  {
                                                                           "keywords":  [
                                                                                            "python",
                                                                                            "py",
                                                                                            "pip",
                                                                                            "pandas",
                                                                                            "numpy",
                                                                                            "django",
                                                                                            "flask",
                                                                                            "pytorch",
                                                                                            "tensorflow"
                                                                                        ],
                                                                           "fileExtensions":  [
                                                                                                  ".py",
                                                                                                  ".pyw",
                                                                                                  ".pyi"
                                                                                              ],
                                                                           "prefix":  "[Python] "
                                                                       },
                                                            "javascript":  {
                                                                               "keywords":  [
                                                                                                "javascript",
                                                                                                "js",
                                                                                                "node",
                                                                                                "npm",
                                                                                                "react",
                                                                                                "vue",
                                                                                                "angular",
                                                                                                "express",
                                                                                                "next.js"
                                                                                            ],
                                                                               "fileExtensions":  [
                                                                                                      ".js",
                                                                                                      ".mjs",
                                                                                                      ".cjs"
                                                                                                  ],
                                                                               "prefix":  "[JavaScript] "
                                                                           },
                                                            "typescript":  {
                                                                               "keywords":  [
                                                                                                "typescript",
                                                                                                "ts",
                                                                                                "tsx",
                                                                                                "deno"
                                                                                            ],
                                                                               "fileExtensions":  [
                                                                                                      ".ts",
                                                                                                      ".tsx",
                                                                                                      ".mts"
                                                                                                  ],
                                                                               "prefix":  "[TypeScript] "
                                                                           },
                                                            "rust":  {
                                                                         "keywords":  [
                                                                                          "rust",
                                                                                          "cargo",
                                                                                          "rustc",
                                                                                          "tokio",
                                                                                          "async-std"
                                                                                      ],
                                                                         "fileExtensions":  [
                                                                                                ".rs"
                                                                                            ],
                                                                         "prefix":  "[Rust] "
                                                                     },
                                                            "go":  {
                                                                       "keywords":  [
                                                                                        "golang",
                                                                                        "go ",
                                                                                        "goroutine"
                                                                                    ],
                                                                       "fileExtensions":  [
                                                                                              ".go"
                                                                                          ],
                                                                       "prefix":  "[Go] "
                                                                   },
                                                            "java":  {
                                                                         "keywords":  [
                                                                                          "java ",
                                                                                          "jvm",
                                                                                          "maven",
                                                                                          "gradle",
                                                                                          "spring",
                                                                                          "kotlin"
                                                                                      ],
                                                                         "fileExtensions":  [
                                                                                                ".java",
                                                                                                ".kt"
                                                                                            ],
                                                                         "prefix":  "[Java] "
                                                                     },
                                                            "csharp":  {
                                                                           "keywords":  [
                                                                                            "c#",
                                                                                            "csharp",
                                                                                            "dotnet",
                                                                                            ".net",
                                                                                            "aspnet",
                                                                                            "unity"
                                                                                        ],
                                                                           "fileExtensions":  [
                                                                                                  ".cs"
                                                                                              ],
                                                                           "prefix":  "[C#] "
                                                                       },
                                                            "sql":  {
                                                                        "keywords":  [
                                                                                         "sql",
                                                                                         "query",
                                                                                         "select",
                                                                                         "database",
                                                                                         "mysql",
                                                                                         "postgres",
                                                                                         "sqlite",
                                                                                         "mongodb"
                                                                                     ],
                                                                        "fileExtensions":  [
                                                                                               ".sql"
                                                                                           ],
                                                                        "prefix":  "[SQL] "
                                                                    },
                                                            "bash":  {
                                                                         "keywords":  [
                                                                                          "bash",
                                                                                          "shell",
                                                                                          "sh ",
                                                                                          "linux",
                                                                                          "terminal",
                                                                                          "cli"
                                                                                      ],
                                                                         "fileExtensions":  [
                                                                                                ".sh",
                                                                                                ".bash"
                                                                                            ],
                                                                         "prefix":  "[Bash] "
                                                                     },
                                                            "powershell":  {
                                                                               "keywords":  [
                                                                                                "powershell",
                                                                                                "ps1",
                                                                                                "pwsh",
                                                                                                "cmdlet"
                                                                                            ],
                                                                               "fileExtensions":  [
                                                                                                      ".ps1",
                                                                                                      ".psm1",
                                                                                                      ".psd1"
                                                                                                  ],
                                                                               "prefix":  "[PowerShell] "
                                                                           }
                                                        },
                                  "clarityAnalysis":  {
                                                          "vagueWords":  {
                                                                             "words":  [
                                                                                           "something",
                                                                                           "stuff",
                                                                                           "thing",
                                                                                           "it",
                                                                                           "this",
                                                                                           "that",
                                                                                           "etc",
                                                                                           "whatever",
                                                                                           "somehow"
                                                                                       ],
                                                                             "penalty":  5
                                                                         },
                                                          "specificityIndicators":  {
                                                                                        "words":  [
                                                                                                      "specifically",
                                                                                                      "exactly",
                                                                                                      "must",
                                                                                                      "should",
                                                                                                      "using",
                                                                                                      "with",
                                                                                                      "in",
                                                                                                      "for"
                                                                                                  ],
                                                                                        "bonus":  3
                                                                                    },
                                                          "minLength":  {
                                                                            "threshold":  10,
                                                                            "penalty":  30
                                                                        },
                                                          "shortLength":  {
                                                                              "threshold":  30,
                                                                              "penalty":  15
                                                                          },
                                                          "contextPattern":  {
                                                                                 "regex":  "(for|to|because|since|using|with|in)\\s+\\w+",
                                                                                 "missingPenalty":  10
                                                                             },
                                                          "formatPattern":  {
                                                                                "regex":  "(format|output|return|show|display|as|like)",
                                                                                "suggestion":  "Consider specifying desired output format"
                                                                            }
                                                      },
                                  "modelOptimizations":  {
                                                             "gemini-2.0-flash":  {
                                                                                      "maxTokens":  8192,
                                                                                      "style":  "balanced",
                                                                                      "prefix":  "",
                                                                                      "temperature":  0.7,
                                                                                      "topP":  0.95
                                                                                  },
                                                             "gemini-2.0-flash-lite":  {
                                                                                           "maxTokens":  4096,
                                                                                           "style":  "concise",
                                                                                           "prefix":  "",
                                                                                           "temperature":  0.5,
                                                                                           "topP":  0.9
                                                                                       },
                                                             "gemini-1.5-pro":  {
                                                                                    "maxTokens":  32768,
                                                                                    "style":  "detailed",
                                                                                    "prefix":  "",
                                                                                    "temperature":  0.7,
                                                                                    "topP":  0.95
                                                                                },
                                                             "gemini-1.5-flash":  {
                                                                                      "maxTokens":  8192,
                                                                                      "style":  "balanced",
                                                                                      "prefix":  "",
                                                                                      "temperature":  0.6,
                                                                                      "topP":  0.9
                                                                                  }
                                                         },
                                  "templates":  {
                                                    "structureWrapper":  {
                                                                             "lowClarity":  "Task: {prompt}\n\nPlease provide a clear, well-structured response.",
                                                                             "codeRequest":  "## Request\n{prompt}\n\n## Requirements\n- Clean, readable code\n- Proper error handling\n- Comments for complex logic",
                                                                             "analysisRequest":  "## Topic\n{prompt}\n\n## Analysis Requirements\n- Structured approach\n- Multiple perspectives\n- Evidence-based conclusions"
                                                                         },
                                                    "fewShotFormat":  {
                                                                          "header":  "\n\nExamples of good responses:\n",
                                                                          "example":  "Q: {question}\nA: {answer}\n\n"
                                                                      }
                                                },
                                  "hooks":  {
                                                "preProcess":  [
                                                                   {
                                                                       "name":  "trimWhitespace",
                                                                       "enabled":  true
                                                                   },
                                                                   {
                                                                       "name":  "normalizeNewlines",
                                                                       "enabled":  true
                                                                   },
                                                                   {
                                                                       "name":  "removeExcessivePunctuation",
                                                                       "enabled":  false
                                                                   }
                                                               ],
                                                "postProcess":  [
                                                                    {
                                                                        "name":  "validateEnhancement",
                                                                        "enabled":  true,
                                                                        "maxLengthIncrease":  2.0
                                                                    }
                                                                ]
                                            },
                                  "api":  {
                                              "endpoints":  {
                                                                "optimize":  "/api/prompt/optimize",
                                                                "analyze":  "/api/prompt/analyze",
                                                                "batch":  "/api/prompt/batch"
                                                            },
                                              "methods":  {
                                                              "optimize":  {
                                                                               "input":  {
                                                                                             "prompt":  "string",
                                                                                             "model":  "string?",
                                                                                             "category":  "string?",
                                                                                             "addExamples":  "boolean?",
                                                                                             "detailed":  "boolean?"
                                                                                         },
                                                                               "output":  {
                                                                                              "originalPrompt":  "string",
                                                                                              "optimizedPrompt":  "string",
                                                                                              "category":  "string",
                                                                                              "language":  "string?",
                                                                                              "clarityScore":  "number",
                                                                                              "enhancements":  "string[]",
                                                                                              "wasEnhanced":  "boolean"
                                                                                          }
                                                                           },
                                                              "analyze":  {
                                                                              "input":  {
                                                                                            "prompt":  "string"
                                                                                        },
                                                                              "output":  {
                                                                                             "score":  "number",
                                                                                             "quality":  "string",
                                                                                             "issues":  "string[]",
                                                                                             "suggestions":  "string[]",
                                                                                             "category":  "string",
                                                                                             "detectedLanguage":  "string?"
                                                                                         }
                                                                          }
                                                          }
                                          },
                                  "geminiIntegration":  {
                                                            "safetySettings":  [
                                                                                   {
                                                                                       "category":  "HARM_CATEGORY_HARASSMENT",
                                                                                       "threshold":  "BLOCK_MEDIUM_AND_ABOVE"
                                                                                   },
                                                                                   {
                                                                                       "category":  "HARM_CATEGORY_HATE_SPEECH",
                                                                                       "threshold":  "BLOCK_MEDIUM_AND_ABOVE"
                                                                                   },
                                                                                   {
                                                                                       "category":  "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                                                                                       "threshold":  "BLOCK_MEDIUM_AND_ABOVE"
                                                                                   },
                                                                                   {
                                                                                       "category":  "HARM_CATEGORY_DANGEROUS_CONTENT",
                                                                                       "threshold":  "BLOCK_MEDIUM_AND_ABOVE"
                                                                                   }
                                                                               ],
                                                            "generationConfig":  {
                                                                                     "candidateCount":  1,
                                                                                     "stopSequences":  [

                                                                                                       ],
                                                                                     "responseMimeType":  "text/plain"
                                                                                 },
                                                            "systemInstructionTemplate":  "{categorySystemPrompt}\n\nUser request optimization applied: {enhancements}"
                                                        },
                                  "cli":  {
                                              "commands":  {
                                                               "optimize":  {
                                                                                "alias":  [
                                                                                              "opt",
                                                                                              "enhance"
                                                                                          ],
                                                                                "description":  "Optimize a prompt before sending",
                                                                                "usage":  "gemini optimize \"your prompt here\"",
                                                                                "flags":  {
                                                                                              "--model":  "Target model for optimization",
                                                                                              "--category":  "Force specific category",
                                                                                              "--show":  "Show optimization details",
                                                                                              "--no-optimize":  "Disable auto-optimization",
                                                                                              "--examples":  "Include few-shot examples"
                                                                                          }
                                                                            },
                                                               "analyze":  {
                                                                               "alias":  [
                                                                                             "check",
                                                                                             "quality"
                                                                                         ],
                                                                               "description":  "Analyze prompt quality without optimizing",
                                                                               "usage":  "gemini analyze \"your prompt here\""
                                                                           }
                                                           },
                                              "environment":  {
                                                                  "GEMINI_AUTO_OPTIMIZE":  {
                                                                                               "type":  "boolean",
                                                                                               "default":  true,
                                                                                               "description":  "Enable automatic prompt optimization"
                                                                                           },
                                                                  "GEMINI_SHOW_ENHANCEMENTS":  {
                                                                                                   "type":  "boolean",
                                                                                                   "default":  false,
                                                                                                   "description":  "Show optimization details in output"
                                                                                               },
                                                                  "GEMINI_MIN_CLARITY":  {
                                                                                             "type":  "number",
                                                                                             "default":  60,
                                                                                             "description":  "Minimum clarity score to trigger enhancement"
                                                                                         }
                                                              }
                                          },
                                  "examples":  {
                                                   "basic":  {
                                                                 "input":  "python sort",
                                                                 "output":  "[Python] python sort\n\nProvide clean, well-documented code. Include error handling where appropriate. Follow best practices for the language.",
                                                                 "category":  "code",
                                                                 "clarityScore":  45,
                                                                 "enhancements":  [
                                                                                      "Added language tag: python",
                                                                                      "Added code-specific instructions"
                                                                                  ]
                                                             },
                                                   "analysis":  {
                                                                    "input":  "compare react vue",
                                                                    "output":  "compare react vue\n\nProvide a structured analysis. Consider multiple perspectives. Support conclusions with reasoning. Use clear headings and sections.",
                                                                    "category":  "analysis",
                                                                    "clarityScore":  55,
                                                                    "enhancements":  [
                                                                                         "Added analysis-specific instructions"
                                                                                     ]
                                                                },
                                                   "lowClarity":  {
                                                                      "input":  "do the thing",
                                                                      "output":  "Task: do the thing\n\nPlease provide a clear, well-structured response.\n\nProvide step-by-step instructions. Include verification steps. Mention prerequisites if any.",
                                                                      "category":  "task",
                                                                      "clarityScore":  25,
                                                                      "enhancements":  [
                                                                                           "Added structure wrapper",
                                                                                           "Added task-specific instructions"
                                                                                       ]
                                                                  }
                                               }
                              },
    "ui":  {
               "$schema":  "https://json-schema.org/draft/2020-12/schema",
               "name":  "HYDRA Show Enhancements Configuration",
               "version":  "1.0.0",
               "description":  "Configuration for displaying prompt optimization enhancements and metadata",
               "feature":  {
                               "name":  "showEnhancements",
                               "type":  "boolean",
                               "default":  true,
                               "description":  "When enabled, displays detailed information about prompt optimizations applied",
                               "scope":  [
                                             "global",
                                             "session",
                                             "request"
                                         ],
                               "priority":  "request \u003e session \u003e global \u003e environment \u003e default"
                           },
               "output":  {
                              "format":  {
                                             "type":  "structured",
                                             "options":  [
                                                             "structured",
                                                             "compact",
                                                             "json",
                                                             "silent"
                                                         ],
                                             "default":  "structured"
                                         },
                              "colors":  {
                                             "enabled":  true,
                                             "scheme":  {
                                                            "header":  {
                                                                           "foreground":  "Cyan",
                                                                           "style":  "Bold"
                                                                       },
                                                            "category":  {
                                                                             "foreground":  "Yellow"
                                                                         },
                                                            "clarity":  {
                                                                            "excellent":  {
                                                                                              "foreground":  "Green",
                                                                                              "threshold":  90
                                                                                          },
                                                                            "good":  {
                                                                                         "foreground":  "Green",
                                                                                         "threshold":  75
                                                                                     },
                                                                            "fair":  {
                                                                                         "foreground":  "Yellow",
                                                                                         "threshold":  60
                                                                                     },
                                                                            "needsWork":  {
                                                                                              "foreground":  "DarkYellow",
                                                                                              "threshold":  40
                                                                                          },
                                                                            "poor":  {
                                                                                         "foreground":  "Red",
                                                                                         "threshold":  0
                                                                                     }
                                                                        },
                                                            "enhancement":  {
                                                                                "foreground":  "Magenta"
                                                                            },
                                                            "suggestion":  {
                                                                               "foreground":  "DarkCyan"
                                                                           },
                                                            "language":  {
                                                                             "foreground":  "Blue"
                                                                         },
                                                            "warning":  {
                                                                            "foreground":  "Yellow",
                                                                            "style":  "Bold"
                                                                        },
                                                            "error":  {
                                                                          "foreground":  "Red",
                                                                          "style":  "Bold"
                                                                      }
                                                        }
                                         },
                              "symbols":  {
                                              "bullet":  "â€˘",
                                              "arrow":  "â†’",
                                              "check":  "âś“",
                                              "cross":  "âś—",
                                              "info":  "â„ą",
                                              "warning":  "âš ",
                                              "enhancement":  "âšˇ",
                                              "category":  "đź“",
                                              "clarity":  "đź“Š",
                                              "language":  "đź’»"
                                          }
                          },
               "displayFields":  {
                                     "always":  [
                                                    "category",
                                                    "clarityScore",
                                                    "clarityQuality"
                                                ],
                                     "whenEnhanced":  [
                                                          "enhancements",
                                                          "optimizedPrompt"
                                                      ],
                                     "optional":  [
                                                      "originalPrompt",
                                                      "language",
                                                      "clarityIssues",
                                                      "claritySuggestions",
                                                      "modelOptimization",
                                                      "wasEnhanced"
                                                  ],
                                     "metadata":  [
                                                      "processingTimeMs",
                                                      "tokenEstimate",
                                                      "cacheHit"
                                                  ]
                                 },
               "enhancementTypes":  {
                                        "model-prefix":  {
                                                             "id":  "model-prefix",
                                                             "displayName":  "Added model-specific prefix",
                                                             "addedText":  {
                                                                               "qwen2.5-coder":  "You are an expert programmer. "
                                                                           }
                                                         },
                                        "code-instructions":  {
                                                                  "id":  "code-instructions",
                                                                  "displayName":  "Added code-specific instructions",
                                                                  "addedText":  "Provide clean, well-documented code. Include error handling where appropriate. Follow best practices for the language."
                                                              },
                                        "analysis-instructions":  {
                                                                      "id":  "analysis-instructions",
                                                                      "displayName":  "Added analysis-specific instructions",
                                                                      "addedText":  "Provide a structured analysis. Consider multiple perspectives. Support conclusions with reasoning."
                                                                  },
                                        "language-tag":  {
                                                             "id":  "language-tag",
                                                             "displayName":  "Added language tag",
                                                             "format":  "[{language}] "
                                                         },
                                        "structure-wrapper":  {
                                                                  "id":  "structure-wrapper",
                                                                  "displayName":  "Added structure wrapper",
                                                                  "format":  "Task: {prompt}\n\nPlease provide a clear, well-structured response."
                                                              }
                                    },
               "clarityScoring":  {
                                      "baseScore":  100,
                                      "penalties":  {
                                                        "tooShort":  {
                                                                         "threshold":  10,
                                                                         "penalty":  30
                                                                     },
                                                        "briefPrompt":  {
                                                                            "threshold":  30,
                                                                            "penalty":  15
                                                                        },
                                                        "vagueWords":  {
                                                                           "penaltyEach":  5,
                                                                           "words":  [
                                                                                         "something",
                                                                                         "stuff",
                                                                                         "thing",
                                                                                         "etc",
                                                                                         "whatever"
                                                                                     ]
                                                                       },
                                                        "missingContext":  {
                                                                               "penalty":  10
                                                                           }
                                                    },
                                      "bonuses":  {
                                                      "specificIndicators":  {
                                                                                 "bonusEach":  3,
                                                                                 "words":  [
                                                                                               "specifically",
                                                                                               "exactly",
                                                                                               "must",
                                                                                               "should"
                                                                                           ]
                                                                             }
                                                  },
                                      "qualityLabels":  {
                                                            "excellent":  {
                                                                              "minScore":  90
                                                                          },
                                                            "good":  {
                                                                         "minScore":  75
                                                                     },
                                                            "fair":  {
                                                                         "minScore":  60
                                                                     },
                                                            "needsImprovement":  {
                                                                                     "minScore":  40
                                                                                 },
                                                            "poor":  {
                                                                         "minScore":  0
                                                                     }
                                                        }
                                  },
               "configuration":  {
                                     "locations":  {
                                                       "global":  "ai-handler/ai-config.json â†’ settings.promptOptimizer.showEnhancements",
                                                       "session":  "ai-handler/ai-state.json â†’ session.showEnhancements",
                                                       "gemini":  "~/.gemini/extensions/ollama-hydra/prompt-optimizer-gemini.json â†’ settings.showEnhancements"
                                                   }
                                 },
               "examples":  {
                                "structured":  [
                                                   "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
                                                   "â•‘  âšˇ PROMPT OPTIMIZATION                                       â•‘",
                                                   "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•Ł",
                                                   "â•‘  đź“ Category:  code                                          â•‘",
                                                   "â•‘  đź’» Language:  python                                        â•‘",
                                                   "â•‘  đź“Š Clarity:   72/100 (Fair)                                 â•‘",
                                                   "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•Ł",
                                                   "â•‘  âšˇ Enhancements Applied:                                     â•‘",
                                                   "â•‘    â€˘ Added language tag: python                              â•‘",
                                                   "â•‘    â€˘ Added code-specific instructions                        â•‘",
                                                   "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ť"
                                               ],
                                "compact":  "[code|python] Clarity: 72/100 (Fair) | +2 enhancements"
                            },
               "integration":  {
                                   "powershell":  {
                                                      "enableGlobally":  "$config.settings.promptOptimizer.showEnhancements = $true",
                                                      "disableGlobally":  "$config.settings.promptOptimizer.showEnhancements = $false",
                                                      "function":  "Set-AIConfig -ShowEnhancements $true"
                                                  },
                                   "environment":  {
                                                       "AI_SHOW_ENHANCEMENTS":  "true|false",
                                                       "AI_ENHANCEMENT_FORMAT":  "structured|compact|json|silent"
                                                   },
                                   "cli":  {
                                               "--show-enhancements":  "Enable for this request",
                                               "--no-enhancements":  "Disable for this request",
                                               "-ef \u003cformat\u003e":  "Set output format"
                                           }
                               },
               "metadata":  {
                                "_meta.promptOptimization":  {
                                                                 "applied":  "boolean",
                                                                 "originalPrompt":  "string",
                                                                 "optimizedPrompt":  "string",
                                                                 "category":  "string",
                                                                 "language":  "string|null",
                                                                 "clarity":  {
                                                                                 "score":  "number",
                                                                                 "quality":  "string",
                                                                                 "issues":  "array",
                                                                                 "suggestions":  "array"
                                                                             },
                                                                 "enhancements":  {
                                                                                      "applied":  "array",
                                                                                      "count":  "number",
                                                                                      "types":  "array"
                                                                                  },
                                                                 "processing":  {
                                                                                    "timeMs":  "number",
                                                                                    "cached":  "boolean",
                                                                                    "timestamp":  "ISO string"
                                                                                }
                                                             }
                            },
               "defaults":  {
                                "showEnhancements":  true,
                                "outputFormat":  "structured",
                                "colorsEnabled":  true,
                                "autoOptimize":  true,
                                "lowClarityThreshold":  60
                            }
           }
}
