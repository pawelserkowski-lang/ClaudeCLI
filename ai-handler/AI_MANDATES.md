# AI OPERATIONAL MANDATES (PROTOCOL: ZAWSZE)

> **STATUS:** ACTIVE | **VERSION:** 2.0
> **STRATEGY:** CLOUD BRAIN (Claude) / LOCAL MUSCLE (Ollama)
> **MEMORY:** SERENA CORE (AUTO-SAVE) + ContextOptimizer

Niniejszy dokument definiuje nienaruszalne zasady (MANDATES) dla systemu AI. KaÅ¼dy agent musi przestrzegaÄ‡ poniÅ¼szych reguÅ‚.

---

## 1. PAMIÄ˜Ä† I KONTEKST (Memory Strategy)

### 1.1 ProtokÃ³Å‚ sprawdzania pamiÄ™ci

| Krok | Akcja | Funkcja | Cel |
|------|-------|---------|-----|
| **1** | SprawdÅº pamiÄ™Ä‡ Serena | `Get-AllSerenaMemories` | 25 slotÃ³w, ~4000 tokenÃ³w |
| **2** | Weryfikuj cache MCP | `Get-MCPCacheStats` | 5 min TTL |
| **3** | Odczytaj historiÄ™ sesji | `Get-SessionState` | Decyzje, pliki, tokeny |
| **4** | Kompresuj jeÅ›li trzeba | `Compress-Context` | 89% oszczÄ™dnoÅ›ci |

### 1.2 Zasady

*   **ZAWSZE** sprawdzaj pamiÄ™Ä‡ `Serena_Core` oraz peÅ‚nÄ… historiÄ™ czatÃ³w przed udzieleniem odpowiedzi.
*   **ZAWSZE** wykonuj `auto_save` nowych faktÃ³w do pamiÄ™ci dÅ‚ugoterminowej natychmiast po wygenerowaniu.
*   **ZAWSZE** maksymalizuj uÅ¼ycie okna kontekstowego. Kompresja tylko gdy zbliÅ¼asz siÄ™ do limitu.
*   **ZAWSZE** cachuj wyniki read-only MCP calls (5 minut TTL).

### 1.3 Funkcje ContextOptimizer

```powershell
# Estymacja tokenÃ³w
Get-TokenEstimate -Text "..." -Language "auto"  # en, pl, code

# Cache MCP
$cached = Get-CachedMCPResult -ToolName "read_file" -Parameters @{path="..."}
Set-CachedMCPResult -ToolName "..." -Parameters @{} -Result @{}

# Kompresja
$compressed = Compress-Context -Text $longText -MaxTokens 2000 -Strategy "smart"

# Serena memories
Save-ToSerenaMemory -Name "session_notes" -Content "..." -Category "session"
Get-AllSerenaMemories | Format-Table

# Session tracking
Add-SessionDecision "Decided to use approach X"
Add-SessionFile "modified.ps1"
Get-SessionState
```

---

## 2. ARCHITEKTURA HYBRYDOWA (Brain + Muscle)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ§  BRAIN (Cloud)          â”‚     â”‚       ğŸ’ª MUSCLE (Local)          â”‚
â”‚        Anthropic/OpenAI          â”‚     â”‚       Ollama/Desktop Commander   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Analiza logiczna i strategicznaâ”‚     â”‚ âœ“ Egzekucja kodu i skryptÃ³w      â”‚
â”‚ âœ“ Architektura systemÃ³w          â”‚     â”‚ âœ“ Operacje na plikach            â”‚
â”‚ âœ“ Pisanie skomplikowanego kodu   â”‚     â”‚ âœ“ Testy i build                  â”‚
â”‚ âœ“ RozwiÄ…zywanie konfliktÃ³w       â”‚     â”‚ âœ“ Proste przetwarzanie tekstu    â”‚
â”‚ âœ“ Wieloetapowe wnioskowanie      â”‚     â”‚ âœ“ Self-correction (phi3:mini)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.1 PodziaÅ‚ rÃ³l

| Typ zadania | Provider | Model | Koszt |
|-------------|----------|-------|-------|
| Proste pytania | Ollama | llama3.2:3b | $0 |
| Generowanie kodu | Ollama | qwen2.5-coder:1.5b | $0 |
| Walidacja kodu | Ollama | phi3:mini | $0 |
| ZÅ‚oÅ¼ona analiza | Anthropic | Claude Haiku | $0.80/$4 |
| Architektura | Anthropic | Claude Sonnet | $3/$15 |
| Krytyczne zadania | Anthropic | Claude Opus | $15/$75 |

---

## 3. WIELOWÄ„TKOWOÅšÄ† (Parallel Execution)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ZASADA NADRZÄ˜DNA: KaÅ¼da operacja moÅ¼liwa do zrÃ³wnoleglenia     â”‚
â”‚                    MUSI byÄ‡ wykonana rÃ³wnolegle                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1 Klasyfikacja operacji

| Typ | Wykonanie | PrzykÅ‚ady |
|-----|-----------|-----------|
| **READ-ONLY** | Zawsze rÃ³wnolegle | `read_file`, `find_symbol`, `grep`, `list_directory` |
| **SIDE-EFFECTS** | Sekwencyjnie | `write_file`, `edit_block` |
| **AI BATCH** | Parallel (max 16) | `Invoke-AIBatch`, `Task` tool |
| **MCP CALLS** | Batch w jednej wiadomoÅ›ci | Multiple tool calls |

### 3.2 Wzorce

```powershell
# PowerShell parallel
$items | Invoke-Parallel { Process-Item $_ } -ThrottleLimit 8

# AI batch
Invoke-AIBatch -Prompts @("Q1", "Q2", "Q3") -MaxConcurrent 4

# MCP batch (Claude MUSI wysÅ‚aÄ‡ razem)
# âœ… DOBRZE: [read_file: a.txt] [read_file: b.txt] [find_symbol: MyClass]
# âŒ Å¹LE:   Osobne wiadomoÅ›ci dla kaÅ¼dego tool call
```

---

## 4. FALLBACK CHAIN (Rate Limit Recovery)

### 4.1 KolejnoÅ›Ä‡ fallback

```
Opus wyczerpany? â†’
  1. ğŸ”‘ ANTHROPIC_API_KEY_2 (ten sam model, inny klucz)
  2. ğŸ”‘ ANTHROPIC_API_KEY_3 (trzeci klucz jeÅ›li istnieje)
  3. ğŸ“‰ Sonnet 4 (niÅ¼szy model)
  4. ğŸ“‰ Sonnet 3.5 â†’ Haiku (dalsze obniÅ¼anie)
  5. ğŸ”„ OpenAI (inny provider)
  6. ğŸ”„ Ollama local (fallback ostateczny)
```

### 4.2 API Key Rotation

```powershell
# SprawdÅº dostÄ™pne klucze
Get-AvailableApiKeys -Provider "anthropic"

# SprawdÅº czy jest alternatywny klucz
Test-AlternateKeyAvailable -Provider "anthropic"

# Status rotacji
Get-ApiKeyRotationStatus

# RÄ™czne przeÅ‚Ä…czenie (automatyczne gdy rate limit)
Switch-ToNextApiKey -Provider "anthropic"
```

### 4.3 Konfiguracja kluczy

```powershell
# Ustaw drugi klucz API (User scope - trwaÅ‚y)
[Environment]::SetEnvironmentVariable('ANTHROPIC_API_KEY_2', 'sk-ant-api03-...', 'User')

# Weryfikacja
$env:ANTHROPIC_API_KEY_2
```

---

## 5. OPTYMALIZACJA KOSZTÃ“W (Cost Efficiency)

### 5.1 Priorytet providerÃ³w

| Priorytet | Provider | Model | Koszt/1K tokens | UÅ¼ycie |
|-----------|----------|-------|-----------------|--------|
| **1** | Ollama | llama3.2:3b | $0.00 | **DOMYÅšLNY** |
| **2** | Groq | llama-3.3-70b | Free tier | Szybki cloud |
| **3** | Anthropic | Haiku | $0.80/$4 | Proste cloud |
| **4** | Anthropic | Sonnet | $3/$15 | ZÅ‚oÅ¼one |
| **5** | Anthropic | Opus | $15/$75 | Krytyczne |

### 5.2 Ustawienia

```json
{
  "preferLocal": true,
  "costOptimization": true,
  "autoFallback": true,
  "rateLimitThreshold": 0.85
}
```

### 5.3 ReguÅ‚y

*   **ZAWSZE** `preferLocal: true` - proste zadania lokalnie.
*   **ZAWSZE** sprawdzaj `Get-SystemLoad` przed decyzjÄ… o providerze.
*   **ZAWSZE** uÅ¼ywaj `Invoke-AIBatch` dla wielu niezaleÅ¼nych promptÃ³w.
*   **NIGDY** nie uÅ¼ywaj Opus do prostych zadaÅ„.

---

## 6. MODUÅY AI HANDLER (Auto-loaded at startup)

### 6.1 Fazy Å‚adowania (AIFacade)

| Faza | ModuÅ‚y | Opis |
|------|--------|------|
| **1** | Utils | JsonIO, Health, Validation |
| **2** | Core | Constants, Config, State |
| **3** | Infrastructure | RateLimiter, ModelSelector |
| **4** | Providers | Ollama, Anthropic, OpenAI |
| **4.5** | Fallback | ApiKeyRotation, ProviderFallback |
| **5** | Advanced | SelfCorrection, FewShot, ContextOptimizer... |

### 6.2 Komendy slash

| Komenda | Funkcja | ModuÅ‚ |
|---------|---------|-------|
| `/ai <query>` | Quick local query | AIModelHandler |
| `/ai-batch` | Parallel batch | AIModelHandler |
| `/ai-status` | Provider status | AIModelHandler |
| `/self-correct` | Code validation | SelfCorrection |
| `/speculate` | Model racing | SpeculativeDecoding |
| `/few-shot` | History learning | FewShotLearning |
| `/optimize-context` | Token dashboard | ContextOptimizer |

---

## 7. CHECKLIST (Przed kaÅ¼dym zadaniem)

```
â–¡ SprawdÅº pamiÄ™Ä‡ Serena (Get-AllSerenaMemories)
â–¡ SprawdÅº cache MCP (Get-MCPCacheStats)
â–¡ SprawdÅº obciÄ…Å¼enie CPU (Get-SystemLoad)
â–¡ Wybierz provider (preferLocal â†’ cloud fallback)
â–¡ Rozbij na pod-zadania jeÅ›li moÅ¼liwe
â–¡ Uruchom rÃ³wnolegle read-only operacje
â–¡ Zapisz wyniki do pamiÄ™ci sesji
```

---

> *"Trzy gÅ‚owy, jeden cel. HYDRA wykonuje rÃ³wnolegle."*
